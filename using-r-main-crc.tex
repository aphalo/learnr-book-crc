\documentclass[krantz2]{krantz}\usepackage{knitr}

\usepackage{color}

% \usepackage[scale=0.15,text={\copyright\ 2023 P. J. Aphalo, draft of \today}]{draftwatermark}

\usepackage{hologo}

\usepackage{csquotes}

\usepackage{graphicx}
\DeclareGraphicsExtensions{.jpg,.pdf,.png}

\usepackage{animate}

\usepackage[style=authoryear-comp,giveninits,sortcites,maxcitenames=2,%
    mincitenames=1,maxbibnames=10,minbibnames=10,backref,uniquename=mininit,%
    uniquelist=minyear,sortgiveninits=true,backend=biber]{biblatex}

\newcommand{\href}[2]{\emph{#2} (\url{#1})}

\usepackage{framed}

\usepackage{abbrev}
\usepackage{usingr}

\usepackage{imakeidx}

% for drawing flowcharts
\usepackage{tikz}
\usetikzlibrary{shapes.geometric,shapes.symbols,shapes.multipart,positioning,fit,arrows,matrix,backgrounds}
\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black]
%tight boxes
\tikzstyle{tprocess} = [rectangle, minimum width=2cm, minimum height=0.66cm, text centered, draw=black]
\tikzstyle{enclosure} = [rectangle, minimum width=3.4cm, minimum height=3cm, text centered, draw=black]
\tikzstyle{decision} = [diamond, aspect=2, minimum width=3cm, minimum height=1cm, text centered, draw=black]
\tikzstyle{arrow} = [thick,->,>=latex]

\tikzset{
 a/.style
  = {node distance=4em, text width=0.1em, minimum height=4em},
 b/.style
  = {rectangle, draw, fill=gray!10, node distance=4em, text width=6em,
     text centered, rounded corners, minimum height=4em, thick},
 bo/.style
  = {rectangle, draw, fill=orange!10, node distance=4em, text width=6em,
     text centered, rounded corners, minimum height=4em, thick},
 c/.style
  = {circle, draw, dashed, fill=orange!10, inner sep = 0pt, node distance=4em, text width=6em,
     text centered, thick},
 cc/.style
  = {circle, draw, dashed, fill=orange!10, inner sep = 0pt, node distance=4em, text width=3em,
     text centered, thick},
 l/.style
  = {draw, -latex, ultra thick},
 aa/.style
  = {node distance=4em, text width=0em, minimum height=0.5ex},
 ll/.style
  = {draw, {open triangle 45} -, thick},
}

%\usepackage{polyglossia}
%\setdefaultlanguage{english}

% floats
\setcounter{topnumber}{3}
\setcounter{bottomnumber}{3}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{0.90}
\renewcommand{\bottomfraction}{0.90}
\renewcommand{\textfraction}{0.10}
\renewcommand{\floatpagefraction}{0.70}
\renewcommand{\dbltopfraction}{0.90}
\renewcommand{\dblfloatpagefraction}{0.70}

% Include subsections as deepest nested in TOC
\setcounter{tocdepth}{2}
% Subsections as deepest numbered
\setcounter{secnumdepth}{2}

% ensure page numbers are aligned in TOC
\makeatletter
\renewcommand{\@pnumwidth}{2.05em}
\makeatother

\addbibresource{rbooks.bib}
\addbibresource{references.bib}

\makeindex[title=General Index]
\makeindex[name=rindex,title=Alphabetic Index of \Rlang Names]
\makeindex[name=rcatsidx,title=Index of \Rlang Names by Category]
\makeindex[name=faqindex,title=Frequently Asked Questions,columns=1]
\makeindex[name=cloudindex] % used for wordcloud
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
\hyphenation{pro-cess-ing paren-the-ses spe-cif-ic au-thors in-ter-act-ed lim-it}

\title{\Huge{\fontseries{ub}\sffamily Learn R\\{\Large As a Language}}}

\author{Pedro J. Aphalo}

\date{Helsinki, \today}

% knitr setup

















\frontmatter

\maketitle

\newpage

\setcounter{page}{5} %previous pages will be reserved for frontmatter to be added in later.
\tableofcontents
\listoffigures
\listoftables



%\include{frontmatter/foreword}



\mainmatter




















% !Rnw root = appendix.main.Rnw



\chapter{Base R and Extensions: Data Sharing}\label{chap:R:data:io}\label{sec:data:io}

\begin{VF}
Most programmers have seen them, and most good programmers realize they've written at least one. They are huge, messy, ugly programs that should have been short, clean, beautiful programs.

\VA{John Bentley}{\emph{Programming Pearls}, 1986}
\end{VF}



\section{Aims of this chapter}

Base \Rlang and the recommended packages (installed by default) include several functions for importing and exporting data. Contributed packages provide both replacements for some of these functions and support for several additional file formats. In the present chapter, I aim at describing both data input and output covering in detail only the most common ``foreign'' data formats (those not native to \Rlang).

Data file formats that are foreign to \Rlang are not always well defined, making it necessary to reverse-engineer the algorithms needed to read them. These formats, even when clearly defined, may be updated by the developers of the foreign software that writes the files. Consequently, developing software to read and write files using foreign formats can easily result in long, messy, and ugly \Rlang scripts. We can also unwillingly write code that usually works but occasionally fails with specific files, or even worse, occasionally silently corrupts the imported data. The aim of this chapter is to provide guidance for finding functions for reading data encoded using foreign formats, covering both base \Rlang, including the \pkgname{foreign} package, and independently contributed packages. Such functions are well tested or validated.

In this chapter you will familiarize yourself with how to exchange data between \Rlang and other applications. The functions \code{save()} and \code{load()}, and \code{saveRDS()} and  \code{readRDS()}, all of which save and read data in \Rlang's native formats, are described in sections \ref{sec:data:rda} and \ref{sec:data:rds} starting on page \pageref{sec:data:rda}.

\begin{warningbox}
  Several examples in this chapter make use of functions from the \pkgname{tidyverse} for data wrangling because some of the packages used to import data in ``foreign'' formats are themselves part of the \pkgname{tidyverse}. Some of the functions used appear in this chapter for the first time in the book.
\end{warningbox}

\section{Introduction}

The first step in any data analysis with \Rlang is to input or read-in the data. Available sources of data are many and data can be stored or transmitted using various formats, both based on text or binary encodings. It is crucial that data is not altered (corrupted) when read and that in the eventual case of an error, errors are clearly reported. Most dangerous are silent non-catastrophic errors.

The very welcome increase of awareness of the need for open availability of data, makes the output of data from \Rlang into well-defined data-exchange formats another crucial step. Consequently, in many cases an important step in data analysis is to export the data for submission to a repository, in addition to publication of the results of the analysis.

Faster internet access to data sources and cheaper random-access memory (RAM) has made it possible to efficiently work with relatively large data sets in \Rlang. That \Rlang keeps all data in memory (RAM), imposes limits to the size of data \Rlang functions can operate on. For data sets large enough not to fit in computer RAM, one can use selective reading of data from flat files, or from databases outside of \Rlang.

Some contributed \Rlang packages support import of data saved in the same formats already supported by base \Rlang, but using different compromises between reliability, easy of use and performance. Functions in base \Rlang tend to prioritize reliability and protection from data corruption while some contributed packages prioritize performance. Other contributed packages make it possible to import and export data stored in file formats not supported by base \Rlang functions. Some of these formats are subject-area specific while others are in widespread use. Packages supporting direct download of data sets from public repositories are becoming also common.

\section{Packages used in this chapter}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{install.packages}\hlstd{(learnrbook}\hlopt{::}\hlstd{pkgs_ch10_2ed)}
\end{alltt}
\end{kframe}
\end{knitrout}

To run the examples included in this chapter, you need first to load some packages from the library (see section \ref{sec:script:packages} on page \pageref{sec:script:packages} for details on the use of packages).

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(learnrbook)}
\hlkwd{library}\hlstd{(tibble)}
\hlkwd{library}\hlstd{(purrr)}
\hlkwd{library}\hlstd{(stringr)}
\hlkwd{library}\hlstd{(dplyr)}
\hlkwd{library}\hlstd{(tidyr)}
\hlkwd{library}\hlstd{(readr)}
\hlkwd{library}\hlstd{(readxl)}
\hlkwd{library}\hlstd{(xlsx)}
\hlkwd{library}\hlstd{(readODS)}
\hlkwd{library}\hlstd{(pdftools)}
\hlkwd{library}\hlstd{(foreign)}
\hlkwd{library}\hlstd{(haven)}
\hlkwd{library}\hlstd{(xml2)}
\hlkwd{library}\hlstd{(XML)}
\hlkwd{library}\hlstd{(ncdf4)}
\hlkwd{library}\hlstd{(tidync)}
\hlkwd{library}\hlstd{(lubridate)}
\hlkwd{library}\hlstd{(jsonlite)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{warningbox}
Some data sets used in this and other chapters are available in package \pkgname{learnrbook}. In addition to the \Rlang data objects, the package includes files saved in \emph{foreign} formats used in examples of importing data. The files can be either read from the \Rlang library, or from a copy in a local folder. In this chapter the code examples assume the user has copied the folder \code{"extdata"} from the package to the current working folder.

The files can be copied by running the two statements below, assuming the current folder is the one that will be used to run the code examples in this chapter.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{pkg.path} \hlkwb{<-} \hlkwd{system.file}\hlstd{(}\hlstr{"extdata"}\hlstd{,} \hlkwc{package} \hlstd{=} \hlstr{"learnrbook"}\hlstd{)}
\hlkwd{file.copy}\hlstd{(pkg.path,} \hlstr{"."}\hlstd{,} \hlkwc{overwrite} \hlstd{=} \hlnum{TRUE}\hlstd{,} \hlkwc{recursive} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] TRUE
\end{verbatim}
\end{kframe}
\end{knitrout}

Some examples write files to disk, and the statements below ensure that the folder used in these examples exists, creating it if not found.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{save.path} \hlkwb{=} \hlstr{"./data"}
\hlkwa{if} \hlstd{(}\hlopt{!}\hlkwd{dir.exists}\hlstd{(save.path)) \{}
  \hlkwd{dir.create}\hlstd{(save.path)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{warningbox}

\section{File names and operations}\label{sec:files:filenames}
\index{file names!portable}
\index{file operations|(}
The naming of files affects data sharing irrespective of the format used for its encoding. The main difficulty is that different operating systems have different rules governing the syntax used for file names and file paths. In many cases, like when depositing data files in a public repository, we need to ensure that file names are valid across multiple operating systems (OSs). If the script used to create the files is itself expected to be OS agnostic, queries for file names and paths in \Rlang code should not make assumptions on the naming rules or available OS commands. This is especially important when developing \Rlang packages.

\begin{warningbox}
\index{file names!script portability}
For maximum portability, file names should never contain white-space characters and contain at most one dot. For the widest possible portability, underscores should be avoided using dashes instead. As an example, instead of \code{my data.2019.csv}, use \code{my-data-2019.csv}.
\end{warningbox}

\Rlang provides functions which help with portability, by hiding the idiosyncrasies of the different OSs from \Rlang code. In scripts these functions should be preferred over direct call to OS commands (i.e., avoid calls to functions \Rfunction{shell()} or \Rfunction{system()} with OS commands as arguments) whenever possible. As the algorithm needed to extract a file name from a file path is OS specific, \Rlang provides functions such as \Rfunction{basename()}, whose implementation is OS specific but from the side of \Rlang code behave identically---these functions hide the differences among OSs from the user of \Rlang. The chunk below can be expected to work correctly under any OS for which \Rlang is available.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{basename}\hlstd{(}\hlstr{"extdata/my-file.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] "my-file.txt"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{warningbox}
\index{file paths!script portability}
\index{folders|see{file paths}}
\index{file paths!parsing|(}
While in \pgrmname{Unix} and \pgrmname{Linux} folder nesting in file paths is marked with a forward slash character (\verb|/|), under \pgrmname{MS-Windows} it is marked with a backslash character (\verb|\|). Backslash (\verb|\|) is an escape character in \Rlang and interpreted as the start of an embedded special character (see section \ref{sec:calc:character} on page \pageref{sec:calc:character}), while in \Rlang a forward slash (\verb|/|) can be used for file paths under any OS, and escaped backslash (\verb|\\|) is valid only under MS-Windows. Consequently, \verb|/| should be always preferred to \verb|\\| to ensure portability, and is the approach used in this book.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{basename}\hlstd{(}\hlstr{"extdata/my-file.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] "my-file.txt"
\end{verbatim}
\begin{alltt}
\hlkwd{basename}\hlstd{(}\hlstr{"extdata\textbackslash{}\textbackslash{}my-file.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] "my-file.txt"
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{warningbox}

The complementary function to \code{basename()} is \Rfunction{dirname()} and extracts from a full file path the bare path to the containing folder.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{dirname}\hlstd{(}\hlstr{"extdata/my-file.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] "extdata"
\end{verbatim}
\end{kframe}
\end{knitrout}

\index{file paths!parsing|)}
\index{working directory|(}
Functions \Rfunction{getwd()} and \Rfunction{setwd()} can be used to get the path to the current working directory and to set a directory as current, respectively.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# not run}
\hlkwd{getwd}\hlstd{()}
\end{alltt}
\end{kframe}
\end{knitrout}

Function \Rfunction{setwd()} returns the path to the current working directory, allowing to portably restore the working directory to the previous one. Both relative paths (relative to the current working directory), as in the example, or absolute paths (given in full) are accepted as an argument. In mainstream OSs ``\code{.}'' indicates the current directory and ``\code{..}'' the directory above the current one.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# not run}
\hlstd{oldwd} \hlkwb{<-} \hlkwd{setwd}\hlstd{(}\hlstr{".."}\hlstd{)}
\hlkwd{getwd}\hlstd{()}
\end{alltt}
\end{kframe}
\end{knitrout}

The returned value is always an absolute full path, so it remains valid even if the path to the working directory changes more than once before being restored.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# not run}
\hlstd{oldwd}
\hlkwd{setwd}\hlstd{(oldwd)}
\hlkwd{getwd}\hlstd{()}
\end{alltt}
\end{kframe}
\end{knitrout}
\index{working directory|)}

\index{listing files or directories|(}
Function \Rfunction{list.files()} returns a list of names of files and/or directories (= disk folders) portably across OSs. Function \Rfunction{list.dirs()} returns only the names of directories.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{head}\hlstd{(}\hlkwd{list.files}\hlstd{())}
\end{alltt}
\begin{verbatim}
## [1] "abbrev.sty"                             
## [2] "anscombe.svg"                           
## [3] "aphalo-Learn-R-2ed-crc-2023-06-14.pdf"  
## [4] "aphalo-learn-R-2ed-draft-2022-02-01.pdf"
## [5] "Aphalo-Learn-R-2ed-DRAFT-2023-07-04.pdf"
## [6] "aphalo-learn-r-2ed-draft.pdf"
\end{verbatim}
\begin{alltt}
\hlkwd{head}\hlstd{(}\hlkwd{list.dirs}\hlstd{())}
\end{alltt}
\begin{verbatim}
## [1] "."                "./.git"           "./.git/hooks"     "./.git/info"     
## [5] "./.git/logs"      "./.git/logs/refs"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{playground}
In these functions the default argument for parameter \code{path} is the current working directory, under Windows, Unix, and Linux indicated by \code{"."}. Convince yourself that this is indeed the default by calling the functions with an explicit argument. After this, play with the functions passing as argument to \code{path} other existing and non-existent file and directory paths.
\end{playground}

\begin{playground}
Pass different arguments to parameter \code{full.names} of \Rfunction{list.files()} to obtain either a list of file paths or bare file names. Similarly, investigate how the returned list of files is affected by the argument passed to \code{all.names}.
\end{playground}
\index{listing files or directories|)}

Base \Rlang provides several functions for portably working with files, and they are listed in the help page for \code{files} and in individual help pages. Use \code{help("files")} to access the help for this ``family'' of functions. The chunk below exercises some of these functions. 

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwa{if} \hlstd{(}\hlopt{!}\hlkwd{file.exists}\hlstd{(}\hlstr{"xxx.txt"}\hlstd{)) \{}
  \hlkwd{file.create}\hlstd{(}\hlstr{"xxx.txt"}\hlstd{)}
\hlstd{\}}
\end{alltt}
\begin{verbatim}
## [1] TRUE
\end{verbatim}
\begin{alltt}
\hlkwd{file.size}\hlstd{(}\hlstr{"xxx.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 0
\end{verbatim}
\begin{alltt}
\hlkwd{file.info}\hlstd{(}\hlstr{"xxx.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
##         size isdir mode               mtime               ctime
## xxx.txt    0 FALSE  666 2023-10-05 18:35:56 2023-10-05 18:35:56
##                       atime exe
## xxx.txt 2023-10-05 18:35:56  no
\end{verbatim}
\begin{alltt}
\hlkwd{file.rename}\hlstd{(}\hlstr{"xxx.txt"}\hlstd{,} \hlstr{"zzz.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] TRUE
\end{verbatim}
\begin{alltt}
\hlkwd{file.exists}\hlstd{(}\hlstr{"xxx.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] FALSE
\end{verbatim}
\begin{alltt}
\hlkwd{file.exists}\hlstd{(}\hlstr{"zzz.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] TRUE
\end{verbatim}
\begin{alltt}
\hlkwd{file.remove}\hlstd{(}\hlstr{"zzz.txt"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] TRUE
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{playground}
Function \Rfunction{file.path()} can be used to construct a file path from its components in a way that is portable across OSs. Look at the help page and play with the function to assemble some paths that exist in the computer you are using.
\end{playground}
\index{file operations|)}

\section{Opening and closing file connections}\label{sec:io:connections}

Examples in the rest of this chapter use as an argument for the \code{file} formal parameter literal paths or URLs, and complete the reading or writing operations within the call to a function. Sometimes it is necessary to read or write a text file sequentially, one row or record at a time. In such cases it is most efficient to keep the file open between reads and close the connection only when it is no longer needed. See \code{help(connections)} for details about the various functions available and their behavior in different OSs. The code below opens a file connection, reads two lines, first the top one with column headers, then in a separate call to \Rfunction{readLines()}, the two lines or records with data, and finally closes the connection.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{f1} \hlkwb{<-} \hlkwd{file}\hlstd{(}\hlstr{"extdata/not-aligned-ASCII-UK.csv"}\hlstd{,} \hlkwc{open} \hlstd{=} \hlstr{"r"}\hlstd{)} \hlcom{# open for reading}
\hlkwd{readLines}\hlstd{(f1,} \hlkwc{n} \hlstd{=} \hlnum{1}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] "col1,col2,col3,col4"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{readLines}\hlstd{(f1,} \hlkwc{n} \hlstd{=} \hlnum{2}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] "1.0,24.5,346,ABC" "23.4,45.6,78,Z Y"
\end{verbatim}
\begin{alltt}
\hlkwd{close}\hlstd{(f1)}
\end{alltt}
\end{kframe}
\end{knitrout}

When \Rpgrm is used in batch mode, the ``files'' \code{stdin}, \code{stdout} and \code{stderror} can be opened, and data read from, or written to. These \emph{standard} sources and sinks, so familiar to \Clang programmers, allow the use of \Rlang scripts as tools in data pipes coded as shell scripts under Unix and other OSs.

\section{Plain-text files}\label{sec:files:txt}
\index{importing data!text files|(}
In general, text files are the most portable approach to data storage but usually also the least efficient with respect to the size of the file. Text files are composed of encoded characters. This makes them easy to edit with text editors and easy to read from programs written in most programming languages. On the other hand, how the data encoded as characters is arranged can be based on two different approaches: positional or using a specific character as a separator. 

The positional approach is more concise but almost unreadable to humans as the values run into each other. Reading of data stored using a positional approach requires access to a format definition and was common in FORTRAN and COBOL at the time when punch cards were used to store data. In the case of separators, different separators are in common use. Comma-separated values (CSV) encodings use either a comma or semicolon to separate the fields or columns. Tabulator, or tab-separated values (TSV) use the tab character as a column separator. Sometimes white space is used as a separator, most commonly when all values are to be converted to \code{numeric}.

\begin{explainbox}
\textbf{Not all text files are born equal.} When reading text files, and \emph{foreign} binary files which may contain embedded text strings, there is potential for their misinterpretation during the import operation. One common source of problems, is that column headers are to be read as \Rlang names. As earlier discussed, there are strict rules, such as avoiding spaces or special characters if the names are to be used with the normal \Rlang syntax. On import, some functions will attempt to sanitize the names, but others not. Most such names are still accessible in \Rlang statements, but a special syntax is needed to protect them from triggering syntax errors through their interpretation as something different than variable or function names---in \Rlang jargon we say that they need to be quoted.

Some of the things we need to be on the watch for are:
1) Mismatches between the character encoding expected by the function used to read the file, and the encoding used for saving the file---usually because of different locales, i.e., language and country settings.
2) Leading or trailing (invisible) spaces present in the character values or column names---which are almost invisible when data frames are printed.
3) Wrongly guessed column classes---a typing mistake affecting a single value in a column, e.g.,  the wrong kind of decimal marker, can prevent the column from being recognized as numeric.
4) Mismatched decimal marker in \code{CSV} files---the marker depends on the locale (language and country settings).

If you encounter problems after import, such as failure of extraction of data frame columns by name, use function \code{names()} to get the names printed to the console as a character vector. This is useful because character vectors are always printed with each string delimited by quotation marks making leading and trailing spaces clearly visible. The same applies to use of \code{levels()} with factors created with data that might have contained mistakes or white space.

To demonstrate some of these problems, I create a data frame with name sanitation disabled, and in the second statement with sanitation enabled. The first statement is equivalent to the default behavior of functions in package \pkgname{readr} and the second is equivalent to the behavior of base \Rlang functions. \pkgname{readr} prioritizes the integrity of the original data while \Rlang prioritizes compatibility with R's naming rules.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{data.frame}\hlstd{(}\hlkwc{a} \hlstd{=} \hlnum{1}\hlstd{,} \hlstr{"a "} \hlstd{=} \hlnum{2}\hlstd{,} \hlstr{" a"} \hlstd{=} \hlnum{3}\hlstd{,} \hlkwc{check.names} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##   a a   a
## 1 1  2  3
\end{verbatim}
\begin{alltt}
\hlkwd{data.frame}\hlstd{(}\hlkwc{a} \hlstd{=} \hlnum{1}\hlstd{,} \hlstr{"a "} \hlstd{=} \hlnum{2}\hlstd{,} \hlstr{" a"} \hlstd{=} \hlnum{3}\hlstd{)}
\end{alltt}
\begin{verbatim}
##   a a. X.a
## 1 1  2   3
\end{verbatim}
\end{kframe}
\end{knitrout}

An even more subtle case is when characters can be easily confused by the user reading the output, or typing in the data: zero and o (\code{a0} vs.\ \code{aO}) or el and one (\code{al} vs.\ \code{a1}) can be difficult to distinguish in some fonts. When using encodings capable of storing many character shapes, such as unicode, in some cases two characters with almost identical visual shape may be encoded as different characters.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{data.frame}\hlstd{(}\hlkwc{al} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{a1} \hlstd{=} \hlnum{2}\hlstd{,} \hlkwc{aO} \hlstd{=} \hlnum{3}\hlstd{,} \hlkwc{a0} \hlstd{=} \hlnum{4}\hlstd{)}
\end{alltt}
\begin{verbatim}
##   al a1 aO a0
## 1  1  2  3  4
\end{verbatim}
\end{kframe}
\end{knitrout}

Reading data from a text file can result in very odd-looking values stored in \Rlang variables because of a mismatch in encoding, e.g., when a CSV file saved with \pgrmname{MS-Excel} is silently encoded using 16-bit unicode format, but read as an 8-bit unicode encoded file.

The hardest part of all these problems is to diagnose their origin, as function arguments and working environment options can in most cases be used to force the correct decoding of text files with diverse characteristics, origins and vintages once one knows what is required. Function \Rfunction{tools:::showNonASCIIfile()} from the \Rlang \pkgname{tools} package, which is not exported, but available in recent and current (4.3.1) versions of \Rpgrm, can be used to test files for the presence on non-ASCII characters. This function takes as an argument the path to a file, and its companion function \Rfunction{tools:::showNonASCII()} a \code{character} string.
\end{explainbox}

\subsection[Base R and `utils']{Base \Rlang and \pkgname{utils}}
\index{text files!with field markers}
Text files containing data in columns can be divided into two broad groups. Those with fixed-width fields and those with delimited fields. Fixed-width fields were especially common in the early days of \langname{FORTRAN} and \langname{COBOL} when data storage capacity was very limited. These formats are frequently capable of encoding information using fewer characters than when delimited fields are used. The best way of understanding the differences is with examples. Although in this section we exemplify the use of functions by passing a file name as an argument, URLs, and open file descriptors are also accepted (see section \ref{sec:io:connections} on page \pageref{sec:io:connections}).

\begin{warningbox}
Wether columns containing character strings that cannot be converted into numbers are converted into factors or remain as character strings in the returned data frame depends on the value passed to parameter \code{stringsAsFactors}. The default changed in \Rlang version 4.0.0 from \code{TRUE} into \code{FALSE}. If code is to work consistently in old and new versions of \Rlang \code{stringsAsFactors = FALSE} has to be passed explicitly in calls to \Rfunction{read.csv} (the approach used in the book).
\end{warningbox}

In the first example a file with fields solely delimited by ``,'' is read. This is what is called comma-separated-values (CSV) format that can be read and written with \Rfunction{read.csv()} and \Rfunction{write.csv()}, respectively.

The contents of file \code{not-aligned-ASCII-UK.csv} are shown below.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{verbatim}
col1,col2,col3,col4
1.0,24.5,346,ABC
23.4,45.6,78,Z Y
\end{verbatim}
\end{kframe}
\end{knitrout}

The file is read and the returned value stored in a variable named \code{from\_csv\_a.df}, and printed.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_csv_a.df} \hlkwb{<-}
  \hlkwd{read.csv}\hlstd{(}\hlstr{"extdata/not-aligned-ASCII-UK.csv"}\hlstd{,} \hlkwc{stringsAsFactors} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_csv_a.df}
\end{alltt}
\begin{verbatim}
##   col1 col2 col3 col4
## 1  1.0 24.5  346  ABC
## 2 23.4 45.6   78  Z Y
\end{verbatim}
\begin{alltt}
\hlstd{from_csv_a.df[[}\hlstr{"col4"}\hlstd{]]}
\end{alltt}
\begin{verbatim}
## [1] "ABC" "Z Y"
\end{verbatim}
\begin{alltt}
\hlkwd{sapply}\hlstd{(from_csv_a.df, class)}
\end{alltt}
\begin{verbatim}
##        col1        col2        col3        col4 
##   "numeric"   "numeric"   "integer" "character"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{playground}
Read the file \code{not-aligned-ASCII-UK.csv} with function \Rfunction{read.csv2()} instead of \Rfunction{read.csv()}. Although this may look like a waste of time, the point of the exercise is for you to get familiar with \Rlang behavior in case of such a mistake. This will help you recognize similar errors when they happen accidentally, which is quite common when files are shared.
\end{playground}

Example file \code{aligned-ASCII-UK.csv} contains comma-separated-values with added white space to align the columns, to make it easier to read by humans.

The contents of file \code{aligned-ASCII-UK.csv} are shown below.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{verbatim}
col1, col2, col3, col4
 1.0, 24.5,  346,  ABC
23.4, 45.6,   78,  Z Y
\end{verbatim}
\end{kframe}
\end{knitrout}

The file is read and the returned value stored in a variable named \code{from\_csv\_b.df}, and printed.
Although space characters are read as part of the fields, they are ignored when conversion to numeric takes place.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_csv_b.df} \hlkwb{<-}
  \hlkwd{read.csv}\hlstd{(}\hlstr{"extdata/aligned-ASCII-UK.csv"}\hlstd{,} \hlkwc{stringsAsFactors} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_csv_b.df}
\end{alltt}
\begin{verbatim}
##   col1 col2 col3  col4
## 1  1.0 24.5  346   ABC
## 2 23.4 45.6   78   Z Y
\end{verbatim}
\begin{alltt}
\hlstd{from_csv_b.df[[}\hlstr{"col4"}\hlstd{]]}
\end{alltt}
\begin{verbatim}
## [1] "  ABC" "  Z Y"
\end{verbatim}
\begin{alltt}
\hlkwd{sapply}\hlstd{(from_csv_b.df, class)}
\end{alltt}
\begin{verbatim}
##        col1        col2        col3        col4 
##   "numeric"   "numeric"   "integer" "character"
\end{verbatim}
\end{kframe}
\end{knitrout}

By default, column names are sanitized but white space in character strings kept. Passing an additional argument changes this default so that leading and trailing white space are discarded. Most likely the default has been chosen so that by default data integrity is maintained.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_csv_c.df} \hlkwb{<-}
  \hlkwd{read.csv}\hlstd{(}\hlstr{"extdata/aligned-ASCII-UK.csv"}\hlstd{,}
           \hlkwc{stringsAsFactors} \hlstd{=} \hlnum{FALSE}\hlstd{,} \hlkwc{strip.white} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_csv_c.df}
\end{alltt}
\begin{verbatim}
##   col1 col2 col3 col4
## 1  1.0 24.5  346  ABC
## 2 23.4 45.6   78  Z Y
\end{verbatim}
\begin{alltt}
\hlstd{from_csv_c.df[[}\hlstr{"col4"}\hlstd{]]}
\end{alltt}
\begin{verbatim}
## [1] "ABC" "Z Y"
\end{verbatim}
\begin{alltt}
\hlkwd{sapply}\hlstd{(from_csv_c.df, class)}
\end{alltt}
\begin{verbatim}
##        col1        col2        col3        col4 
##   "numeric"   "numeric"   "integer" "character"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{explainbox}
When character strings are converted into factors, leading and trailing white space is retained in the labels of factor levels. Leading and trailing white space are difficult to see when data frames are printed, as shown below. This example shows what problems were frequently encountered in earlier versions of \Rlang, and can still occur when factors are created. The recommended approach is to use the default \code{stringsAsFactors = FALSE} and do the conversion into factors in a separate step.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_csv_b.df} \hlkwb{<-}
  \hlkwd{read.csv}\hlstd{(}\hlstr{"extdata/aligned-ASCII-UK.csv"}\hlstd{,} \hlkwc{stringsAsFactors} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

Using \code{levels()} it can be seen that the labels of the automatically created factor levels contain leading spaces.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{sapply}\hlstd{(from_csv_b.df, class)}
\end{alltt}
\begin{verbatim}
##      col1      col2      col3      col4 
## "numeric" "numeric" "integer"  "factor"
\end{verbatim}
\begin{alltt}
\hlstd{from_csv_b.df[[}\hlstr{"col4"}\hlstd{]]}
\end{alltt}
\begin{verbatim}
## [1]   ABC   Z Y
## Levels:   ABC   Z Y
\end{verbatim}
\begin{alltt}
\hlkwd{levels}\hlstd{(from_csv_b.df[[}\hlstr{"col4"}\hlstd{]])}
\end{alltt}
\begin{verbatim}
## [1] "  ABC" "  Z Y"
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{explainbox}

Decimal points and exponential notation are allowed for floating point values. In English-speaking locales, the decimal mark is a point, while in many other locales it is a comma. The behaviour of \Rlang functions does not change when run under different locales. When a comma is used as decimal marker, we can a semicolon (\verb|;|) is used as field marker.

This handled by using functions \Rfunction{read.csv2()} and \Rfunction{write.csv2()}. Furthermore, parameters \code{dec} and \code{sep} allow setting the decimal marker and field separator to arbitrary character strings. 

Function \Rfunction{read.table()} does the actual work and functions like \Rfunction{read.csv()} only differ in the default arguments for the different parameters. By default, \Rfunction{read.table()} expects fields to be separated by white space (one or more spaces, tabs, new lines, or carriage return).

The contents of file \code{aligned-ASCII.txt} are shown below.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{verbatim}
col1 col2 col3 col4
 1.0 24.5  346 ABC
23.4 45.6   78 "Z Y"
\end{verbatim}
\end{kframe}
\end{knitrout}

The file is read and the returned value stored in a variable named \code{from\_txt\_b.df}, and printed.
Leading and trailing white space are removed because they are recognised as part of the separators. For character strings containing embedded spaces to be decoded as a single value they need to be quoted in the file as in \code{aligned-ASCII.txt} above.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_txt_b.df} \hlkwb{<-}
  \hlkwd{read.table}\hlstd{(}\hlstr{"extdata/aligned-ASCII.txt"}\hlstd{,}
             \hlkwc{stringsAsFactors} \hlstd{=} \hlnum{FALSE}\hlstd{,} \hlkwc{header} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_txt_b.df}
\end{alltt}
\begin{verbatim}
##   col1 col2 col3 col4
## 1  1.0 24.5  346  ABC
## 2 23.4 45.6   78  Z Y
\end{verbatim}
\begin{alltt}
\hlstd{from_txt_b.df[[}\hlstr{"col4"}\hlstd{]]}
\end{alltt}
\begin{verbatim}
## [1] "ABC" "Z Y"
\end{verbatim}
\begin{alltt}
\hlkwd{sapply}\hlstd{(from_txt_b.df, class)}
\end{alltt}
\begin{verbatim}
##        col1        col2        col3        col4 
##   "numeric"   "numeric"   "integer" "character"
\end{verbatim}
\end{kframe}
\end{knitrout}

\index{text files!fixed width fields}
With a fixed-width format, no delimiters are needed. Decoding is based solely on the position of the characters in the line or record. A file like this cannot be interpreted without a description of the format used for saving the data. Files containing data stored in \emph{fixed width format} can be read with function \Rfunction{read.fwf()}. Records for a single observation can be stored in a single or multiple lines. In either case, each line has fields of different but fixed known widths.

Function \Rfunction{read.fortran()} is a wrapper on \Rfunction{read.fwf()} that accepts format definitions similar to those used in \langname{FORTRAN}. One particularity of \langname{FORTRAN} \emph{formatted data transfer} is that the decimal marker can be omitted in the saved file and its position specified as part of the format definition, a trick used to make text files (or stacks of punch cards!) smaller. Modern versions of \langname{FORTRAN} support reading from and writing to other formats like those using field delimiters described above.

The contents of file \code{aligned-ASCII.fwf} are shown below.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{verbatim}
 10245346ABC
234456 78Z Y
\end{verbatim}
\end{kframe}
\end{knitrout}

The file is read and the returned value stored in a variable named \code{from\_fwf\_a.df}, and printed. The format definition is passed as a separate character vector argument, e.g., \code{"2F3.1"} describes the format of the first two columns, \code{"I3"} describes the third column and \code{"A3"} the fourth.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_fwf_a.df} \hlkwb{<-} \hlkwd{read.fortran}\hlstd{(}\hlstr{"extdata/aligned-ASCII.fwf"}\hlstd{,}
                              \hlkwc{format} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"2F3.1"}\hlstd{,} \hlstr{"I3"}\hlstd{,} \hlstr{"A3"}\hlstd{),}
                              \hlkwc{col.names} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"col1"}\hlstd{,} \hlstr{"col2"}\hlstd{,} \hlstr{"col3"}\hlstd{,} \hlstr{"col4"}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{from_fwf_a.df}
\end{alltt}
\begin{verbatim}
##   col1 col2 col3 col4
## 1  1.0 24.5  346  ABC
## 2 23.4 45.6   78  Z Y
\end{verbatim}
\begin{alltt}
\hlstd{from_fwf_a.df[[}\hlstr{"col4"}\hlstd{]]}
\end{alltt}
\begin{verbatim}
## [1] "ABC" "Z Y"
\end{verbatim}
\begin{alltt}
\hlkwd{sapply}\hlstd{(from_fwf_a.df, class)}
\end{alltt}
\begin{verbatim}
##        col1        col2        col3        col4 
##   "numeric"   "numeric"   "integer" "character"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{explainbox}
  The file reading functions described above share with \Rfunction{read.table()} the same parameters. In addition to those described above, other frequently useful parameters are \code{skip} and \code{n}, which can be used to skip lines at the top of a file and limit the number of lines (or records) to read; \code{header}, which accepts a logical argument indicating if the fields in the first text line read should be decoded as column names rather than data; \code{na.strings}, to which can be passed a character vector with strings to be interpreted as \code{NA}; and \code{colClasses}, which provides control of the conversion of the fields to \Rlang classes and possibly skipping some columns altogether. All these parameters are described in the corresponding help pages.
\end{explainbox}

\begin{playground}
In reality  \Rfunction{read.csv()}, \code{read.csv2()} and \Rfunction{read.table()} are the same function with different default arguments to several of their parameters. Study the help page, and by passing suitable arguments, make \Rfunction{read.csv()} behave like \Rfunction{read.table()}, then make \Rfunction{read.table()} behave like \Rfunction{read.csv2()}.
\end{playground}

\begin{explainbox}
A text file can be read as character strings, without attempting to decode them. This is occasionally useful, such as when the decoding is done in a script. In this case, the function used is \code{readLines()}. The returned value is a character vector in which each member string corresponds to one line or record in the file, with the end-of-line markers stripped (see example in section \ref{sec:io:connections} on page \pageref{sec:io:connections}).
\end{explainbox}
\index{importing data!text files|)}

\index{exporting data!text files|(}
Next we give one example of the use of a \emph{write} function matching one of the \emph{read} functions described above. The \Rfunction{write.csv()} function takes as an argument a data frame, or an object that can be coerced into a data frame, converts it to character strings, and saves them to a text file. We first create the data frame that we will write to disk.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{my.df} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{1}\hlopt{:}\hlnum{5}\hlstd{,} \hlkwc{y} \hlstd{=} \hlnum{5}\hlopt{:}\hlnum{1} \hlopt{/} \hlnum{10}\hlstd{,} \hlkwc{z} \hlstd{= letters[}\hlnum{1}\hlopt{:}\hlnum{5}\hlstd{])}
\end{alltt}
\end{kframe}
\end{knitrout}

We write \code{my.df} to a CSV file suitable for an English language locale, and then display its contents.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{write.csv}\hlstd{(my.df,} \hlkwc{file} \hlstd{=} \hlstr{"my-file1.csv"}\hlstd{,} \hlkwc{row.names} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\hlkwd{file.show}\hlstd{(}\hlstr{"my-file1.csv"}\hlstd{,} \hlkwc{pager} \hlstd{=} \hlstr{"console"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{verbatim}
"x","y","z"
1,0.5,"a"
2,0.4,"b"
3,0.3,"c"
4,0.2,"d"
5,0.1,"e"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{explainbox}
In most cases setting, as above, \code{row.names = FALSE} when writing a CSV file will help when it is read. Of course, if row names do contain important information, such as gene tags, you cannot skip writing the row names to the file unless you first copy these data into a column in the data frame. (Row names are stored separately as an attribute in \code{data.frame} objects, see section \ref{sec:calc:attributes} on page \pageref{sec:calc:attributes} for details.)
\end{explainbox}

\begin{playground}
Write the data frame \code{my.df} into text files with functions \Rfunction{write.csv2()} and \Rfunction{write.table()} instead of \Rfunction{read.csv()} and display the files.
\end{playground}

Function \Rfunction{cat()} takes \Rlang objects and writes them after conversion to character strings to the console or a file, inserting one or more characters as separators, by default, a space. This separator can be set through parameter \code{sep}. In our example we set \code{sep} to a new line (entered as the escape sequence \code{"\textbackslash n"}).

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{my.lines} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{"abcd"}\hlstd{,} \hlstr{"hello world"}\hlstd{,} \hlstr{"123.45"}\hlstd{)}
\hlkwd{cat}\hlstd{(my.lines,} \hlkwc{file} \hlstd{=} \hlstr{"my-file2.txt"}\hlstd{,} \hlkwc{sep} \hlstd{=} \hlstr{"\textbackslash{}n"}\hlstd{)}
\hlkwd{file.show}\hlstd{(}\hlstr{"my-file2.txt"}\hlstd{,} \hlkwc{pager} \hlstd{=} \hlstr{"console"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{verbatim}
abcd
hello world
123.45
\end{verbatim}
\end{kframe}
\end{knitrout}
\index{exporting data!text files|)}

\subsection[readr]{\pkgname{readr}}\label{sec:files:readr}
\index{importing data!text files|(}



Package \pkgname{readr} is part of the \pkgname{tidyverse} suite. It defines functions that have different default behavior and that are designed to be faster under different situations than those native to  \Rlang. The functions from package \pkgname{readr} can sometimes wrongly decode their input and rarely even silently do this. Base \Rlang functions do less \emph{guessing}, e.g., the delimiters must be supplied as arguments. The \pkgname{readr} functions guess more properties of the text file format; in most cases they succeed, which is very handy, but occasionally they fail. Automatic guessing can be overridden by passing arguments and this is recommended for scripts that may be reused to read different files in the future. Another important advantage is that these functions read character strings formatted as dates or times directly into columns of class \code{POSIXct}. All \code{write} functions defined in \pkgname{readr} have an \code{append} parameter, which can be used to change the default behavior of overwriting an existing file with the same name, to appending the output at its end.

Although in this section we exemplify the use of these functions by passing a file name as an argument, as is the case with \Rlang native functions, URLs, and open file descriptors are also accepted (see section \ref{sec:io:connections} on page \pageref{sec:io:connections}). Furthermore, if the file name ends in a tag recognizable as indicating a compressed file format, the file will be uncompressed on the fly.

\begin{warningbox}
Functions ``equivalent'' to native \Rlang functions described in the previous section have names formed by replacing the dot with an underscore, e.g.,  \Rfunction{read\_csv()} $\approx$ \Rfunction{read.csv()}. The similarity refers to the format of the files read, but not the order, names, or roles of their formal parameters. For example, function \code{read\_table()} has a slightly different behavior than \Rfunction{read.table()}, although they both read fields separated by white space. Other aspects of the default behavior are also different, for example \pkgname{readr} functions do not convert columns of character strings into factors as \Rlang functions did by default in versions earlier than 4.2.0. Row names are not set in the returned \Rclass{tibble}, which inherits from \Rclass{data.frame}, but is not fully compatible (see section \ref{sec:data:tibble} on page \pageref{sec:data:tibble}).
\end{warningbox}

\begin{warningbox}
  Package \pkgname{readr} is under active development, and functions with the same name from different major versions are not fully compatible. Code chunks for examples from the previous edition of the book no longer work because the new implementation fails to recognize escaped special characters. In addition function \Rfunction{read\_table2()} has been renamed \Rfunction{read\_table()}.
\end{warningbox}

As we can see in this first example, these functions also report to the console the specifications of the columns, which is important when these are guessed from the file contents, or even only from rows near the top of the file.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{read_csv}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/aligned-ASCII-UK.csv"}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Rows: 2 Columns: 4\\\#\# -- Column specification --------------------------------------------------------\\\#\# Delimiter: "{},"{}\\\#\# chr (1): col4\\\#\# dbl (3): col1, col2, col3\\\#\# \\\#\# i Use `spec()` to retrieve the full column specification for this data.\\\#\# i Specify the column types or set `show\_col\_types = FALSE` to quiet this message.}}\begin{verbatim}
## # A tibble: 2 x 4
##    col1  col2  col3 col4 
##   <dbl> <dbl> <dbl> <chr>
## 1   1    24.5   346 ABC  
## 2  23.4  45.6    78 Z Y
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{read_csv}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/not-aligned-ASCII-UK.csv"}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Rows: 2 Columns: 4\\\#\# -- Column specification --------------------------------------------------------\\\#\# Delimiter: "{},"{}\\\#\# chr (1): col4\\\#\# dbl (3): col1, col2, col3\\\#\# \\\#\# i Use `spec()` to retrieve the full column specification for this data.\\\#\# i Specify the column types or set `show\_col\_types = FALSE` to quiet this message.}}\begin{verbatim}
## # A tibble: 2 x 4
##    col1  col2  col3 col4 
##   <dbl> <dbl> <dbl> <chr>
## 1   1    24.5   346 ABC  
## 2  23.4  45.6    78 Z Y
\end{verbatim}
\end{kframe}
\end{knitrout}

Package \pkgname{readr} is under active development, and different major versions are not fully compatible with each other. Because of the misaligned fields in file \code{"not-aligned-ASCII.txt"} in the past we needed to use \Rfunction{read\_table2()}, which allowed misalignment of fields, similarly to \Rfunction{read.table()}. This function has been renamed as \Rfunction{read\_table()} and \Rfunction{read\_table2()} deprecated. However, parsing of both files fails if they are read with \Rfunction{read\_table()}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{read_table}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/aligned-ASCII.txt"}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# \\\#\# -- Column specification --------------------------------------------------------\\\#\# cols(\\\#\# \ \ col1 = col\_double(),\\\#\# \ \ col2 = col\_double(),\\\#\# \ \ col3 = col\_double(),\\\#\# \ \ col4 = col\_character()\\\#\# )}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning: 1 parsing failure.\\\#\# row col \ expected \ \ \ actual \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ file\\\#\# \ \ 2 \ -- 4 columns 5 columns 'extdata/aligned-ASCII.txt'}}\begin{verbatim}
## # A tibble: 2 x 4
##    col1  col2  col3 col4 
##   <dbl> <dbl> <dbl> <chr>
## 1   1    24.5   346 "ABC"
## 2  23.4  45.6    78 "\"Z"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{read_table}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/not-aligned-ASCII.txt"}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# \\\#\# -- Column specification --------------------------------------------------------\\\#\# cols(\\\#\# \ \ col1 = col\_double(),\\\#\# \ \ col2 = col\_double(),\\\#\# \ \ col3 = col\_double(),\\\#\# \ \ col4 = col\_character()\\\#\# )}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning: 1 parsing failure.\\\#\# row col \ expected \ \ \ actual \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ file\\\#\# \ \ 2 \ -- 4 columns 5 columns 'extdata/not-aligned-ASCII.txt'}}\begin{verbatim}
## # A tibble: 2 x 4
##    col1  col2  col3 col4 
##   <dbl> <dbl> <dbl> <chr>
## 1   1    24.5   346 "ABC"
## 2  23.4  45.6    78 "\"Z"
\end{verbatim}
\end{kframe}
\end{knitrout}

Function \Rfunction{read\_delim()} with space as the delimiter needs to be used instead of \Rfunction{read\_table()}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{read_delim}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/not-aligned-ASCII.txt"}\hlstd{,} \hlkwc{delim} \hlstd{=} \hlstr{" "}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Rows: 2 Columns: 4\\\#\# -- Column specification --------------------------------------------------------\\\#\# Delimiter: "{} "{}\\\#\# chr (1): col4\\\#\# dbl (3): col1, col2, col3\\\#\# \\\#\# i Use `spec()` to retrieve the full column specification for this data.\\\#\# i Specify the column types or set `show\_col\_types = FALSE` to quiet this message.}}\begin{verbatim}
## # A tibble: 2 x 4
##    col1  col2  col3 col4 
##   <dbl> <dbl> <dbl> <chr>
## 1   1    24.5   346 ABC  
## 2  23.4  45.6    78 Z Y
\end{verbatim}
\end{kframe}
\end{knitrout}

Function \Rfunction{read\_tsv()} reads files encoded with the tab character as the delimiter, and \Rfunction{read\_fwf()} reads files with fixed width fields. There is, however, no equivalent to \Rfunction{read.fortran()}, supporting implicit decimal points.

\begin{playground}
Use the "wrong" \code{read\_} functions to read the example files used above and/or your own files. As mentioned earlier, forcing errors will help you learn how to diagnose when such errors are caused by coding or data entry mistakes. In this case, as wrongly read data are not always accompanied by error or warning messages, carefully check the returned tibbles for misread data values.
\end{playground}

\begin{explainbox}
The functions from R's package \pkgname{utils} read the whole file as text before attempting to guess the class of the columns or their alignment. This is reliable but slow for text files with many lines. The functions from \pkgname{readr} read by default only the top 1000 lines when guessing the format and class, and then rather blindly read the whole files assuming that the guessed properties also apply to the remaining lines of the file. This is more efficient in the case of such files, but somehow risky. In contrast, the functions from R's package \pkgname{utils} are much faster than those from package \pkgname{readr} at reading files with many fields (or columns) per line.

In earlier versions of \pkgname{readr}, a typical failure to correctly decode fields was when numbers are in increasing order and the field widths continue increasing in the lines below those used for guessing, but this case seems to be, at the time of writing correctly, handled. A guess based on the top 1000 lines of a text file also means that in cases values in lines below \code{guess\_max} lines cannot be converted to numeric, instead of returning a column of character strings as functions from R's package \pkgname{utils}, their values are replaced by numeric \code{NA} values with a warning. To demonstrate this we will drastically reduce \code{guess\_max} from its default so that we can use an for the example a file only a few lines in length.



\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{read_table}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/miss-aligned-ASCII.txt"}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# \\\#\# -- Column specification --------------------------------------------------------\\\#\# cols(\\\#\# \ \ col1 = col\_character(),\\\#\# \ \ col2 = col\_double(),\\\#\# \ \ col3 = col\_double(),\\\#\# \ \ col4 = col\_character()\\\#\# )}}\begin{verbatim}
## # A tibble: 4 x 4
##   col1   col2  col3 col4 
##   <chr> <dbl> <dbl> <chr>
## 1 1.0    24.5   346 ABC  
## 2 2.4    45.6    78 XYZ  
## 3 20.4   45.6    78 XYZ  
## 4 a      20    2500 abc
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{read_table}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/miss-aligned-ASCII.txt"}\hlstd{,} \hlkwc{guess_max} \hlstd{=} \hlnum{3L}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# \\\#\# -- Column specification --------------------------------------------------------\\\#\# cols(\\\#\# \ \ col1 = col\_double(),\\\#\# \ \ col2 = col\_double(),\\\#\# \ \ col3 = col\_double(),\\\#\# \ \ col4 = col\_character()\\\#\# )}}

{\ttfamily\noindent\color{warningcolor}{\#\# Warning: 1 parsing failure.\\\#\# row \ col expected actual \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ file\\\#\# \ \ 4 col1 a double \ \ \ \ \ a 'extdata/miss-aligned-ASCII.txt'}}\begin{verbatim}
## # A tibble: 4 x 4
##    col1  col2  col3 col4 
##   <dbl> <dbl> <dbl> <chr>
## 1   1    24.5   346 ABC  
## 2   2.4  45.6    78 XYZ  
## 3  20.4  45.6    78 XYZ  
## 4  NA    20    2500 abc
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{explainbox}
\index{importing data!text files|)}



\index{exporting data!text files|(}
The \code{write\_} functions from \pkgname{readr} are the counterpart to \code{write.} functions from \pkgname{utils}. In addition to the expected \Rfunction{write\_csv()}, \Rfunction{write\_csv2()}, \Rfunction{write\_tsv()} and \Rfunction{write\_delim()}, \pkgname{readr} provides functions that write \pgrmname{MS-Excel}-friendly CSV files. We demonstrate here the use of \Rfunction{write\_excel\_csv()} to produce a text file with comma-separated fields suitable for import into \pgrmname{MS-Excel}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{write_excel_csv}\hlstd{(my.df,} \hlkwc{file} \hlstd{=} \hlstr{"my-file6.csv"}\hlstd{)}
\hlkwd{file.show}\hlstd{(}\hlstr{"my-file6.csv"}\hlstd{,} \hlkwc{pager} \hlstd{=} \hlstr{"console"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

That saves a file containing the following text:
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{verbatim}
"x","y","z"
1,0.5,"a"
2,0.4,"b"
3,0.3,"c"
4,0.2,"d"
5,0.1,"e"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{playground}
Compare the output from \Rfunction{write\_excel\_csv()} and \Rfunction{write\_csv()}. What is the difference? Does it matter when you import the written CSV file into Excel (in the version you are using, and with the locale settings of your computer)?
\end{playground}

The pair of functions \Rfunction{read\_lines()} and \Rfunction{write\_lines()} read and write character vectors without conversion, similarly to base \Rlang \code{readLines()} and \code{writeLines()}. Functions \Rfunction{read\_file()} and \Rfunction{write\_file()} read and write the contents of a whole text file into, and from, a single character string. Functions \Rfunction{read\_file()} and \Rfunction{write\_file()} can also be used with raw vectors to read and write binary files or text files of unknown encoding.

The contents of the whole file are returned as a character vector of length one, with the embedded new line markers. We use \code{cat()} to print it so these new line characters force the start of a new print-out line.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{one.str} \hlkwb{<-} \hlkwd{read_file}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/miss-aligned-ASCII.txt"}\hlstd{)}
\hlkwd{length}\hlstd{(one.str)}
\end{alltt}
\begin{verbatim}
## [1] 1
\end{verbatim}
\begin{alltt}
\hlkwd{cat}\hlstd{(one.str)}
\end{alltt}
\begin{verbatim}
## col1  col2 col3 col4
## 1.0   24.5  346 ABC
## 2.4   45.6   78 XYZ
## 20.4   45.6   78 XYZ
##  a    20     2500 abc
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{advplayground}
Use \Rfunction{write\_file()} to write a file that can be read with \Rfunction{read\_csv()}.
\end{advplayground}
\index{exporting data!text files|)}

\section{XML and HTML files}
\index{importing data!XML and HTML files|(}

XML files contain text with special markup. Several modern data exchange formats are based on the \langname{XML} standard (see \url{https://www.w3.org/TR/xml/}) which uses schemas for flexibility. Schemas define specific formats, allowing reading of formats not specifically targeted during development of the read functions. Even the modern \langname{XHTML} standard used for web pages is based on such schemas, while \langname{HTML} only differs slightly in its syntax.

\subsection[`xml2']{\pkgname{xml2}}



Package \pkgname{xml2} provides functions for reading and parsing \langname{XTML} and \langname{HTML} files. This is a vast subject, of which I will only give a brief example.

We first read a web page with function \Rfunction{read\_html()}, and explore its structure.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{web_page} \hlkwb{<-} \hlkwd{read_html}\hlstd{(}\hlstr{"https://r.r4photobiology.info/index.html"}\hlstd{)}
\hlkwd{html_structure}\hlstd{(web_page)}
\end{alltt}
\begin{verbatim}
## <html [xmlns, lang, xml:lang]>
##   <head>
##     <meta [charset]>
##     <meta [name, content]>
##     <meta [name, content]>
##     <meta [name, content]>
##     <meta [name, content]>
##     <title>
##       {text}
##     <style>
##       {cdata}
##     <script>
##       {cdata}
##     <script>
##       {cdata}
##     <script>
##       {cdata}
##     <script>
##       {cdata}
##     <script>
##       {cdata}
##     <style [type]>
##       {cdata}
##     <link#quarto-text-highlighting-styles [href, rel]>
##     <script>
##       {cdata}
##     <style [type]>
##       {cdata}
##     <link#quarto-bootstrap [href, rel, data-mode]>
##     <link [rel, href]>
##   <body.fullcontent>
##     {text}
##     <div#quarto-content .page-columns.page-rows-contents.page-layout-article>
##       {text}
##       <main#quarto-document-content .content>
##         <header#title-block-header .quarto-title-block.default>
##           <div.quarto-title>
##             {text}
##             <h1.title>
##               {text}
##             {text}
##             <p.subtitle.lead>
##               {text}
##             {text}
##           {text}
##           <div.quarto-title-meta>
##             {text}
##             <div>
##               {text}
##               <div.quarto-title-meta-heading>
##                 {text}
##               {text}
##               <div.quarto-title-meta-contents>
##                 {text}
##                 <p>
##                   {text}
##                 {text}
##               {text}
##             {text}
##             <div>
##               {text}
##               <div.quarto-title-meta-heading>
##                 {text}
##               {text}
##               <div.quarto-title-meta-contents>
##                 {text}
##                 <p.date>
##                   {text}
##                 {text}
##               {text}
##             {text}
##           {text}
##         <section#what-is-stored-in-this-repository .level2>
##           <h2.anchored [data-anchor-id]>
##             {text}
##           {text}
##           <p>
##             {text}
##             <br>
##             {text}
##             <a [href]>
##               {text}
##             {text}
##           {text}
##         <section#installation .level2>
##           <h2.anchored [data-anchor-id]>
##             {text}
##           {text}
##           <p>
##             {text}
##           {text}
##           <p>
##             {text}
##             <a [href]>
##               {text}
##             {text}
##             <a [href]>
##               {text}
##             {text}
##           {text}
##           <p>
##             {text}
##             <code>
##               {text}
##             {text}
##             <code>
##               {text}
##             {text}
##           {text}
##           <div.cell>
##             {text}
##             <div#cb1 .sourceCode.cell-code>
##               <pre.sourceCode.r.code-with-copy>
##                 <code.sourceCode.r>
##                   <span#cb1-1>
##                     <a [href, aria-hidden, tabindex]>
##                     {text}
##                     <span.ot>
##                       {text}
##                     {text}
##                     <span.fu>
##                       {text}
##                     {text}
##                     <span.st>
##                       {text}
##                     {text}
##                   {text}
##                   <span#cb1-2>
##                     <a [href, aria-hidden, tabindex]>
##                     <span.cf>
##                       {text}
##                     {text}
##                     <span.fu>
##                       {text}
##                     {text}
##                   {text}
##                   <span#cb1-3>
##                     <a [href, aria-hidden, tabindex]>
##                     {text}
##                     <span.st>
##                       {text}
##                     {text}
##                     <span.ot>
##                       {text}
##                     {text}
##                     <span.st>
##                       {text}
##                   {text}
##                   <span#cb1-4>
##                     <a [href, aria-hidden, tabindex]>
##                     {text}
##                   {text}
##                   <span#cb1-5>
##                     <a [href, aria-hidden, tabindex]>
##                     {text}
##                     <span.st>
##                       {text}
##                     {text}
##                     <span.ot>
##                       {text}
##                     {text}
##                     <span.st>
##                       {text}
##                   {text}
##                   <span#cb1-6>
##                     <a [href, aria-hidden, tabindex]>
##                     <span.fu>
##                       {text}
##                     {text}
##                     <span.at>
##                       {text}
##                     {text}
##                 <button.code-copy-button [title]>
##                   <i.bi>
##             {text}
##           {text}
##       {comment}
##       <script#quarto-html-after-body [type]>
##         {cdata}
##     {text}
##     {comment}
##     {text}
\end{verbatim}
\end{kframe}
\end{knitrout}

Next we extract the text from its \code{title} attribute, using functions \Rfunction{xml\_find\_all()} and \Rfunction{xml\_text()}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{xml_text}\hlstd{(}\hlkwd{xml_find_all}\hlstd{(web_page,} \hlstr{".//title"}\hlstd{))}
\end{alltt}
\begin{verbatim}
## [1] "R for photobiology repository"
\end{verbatim}
\end{kframe}
\end{knitrout}

The functions defined in this package can be used to ``harvest'' data from web pages, but also to read data from files using formats that are defined through \langname{XML} schemas.
\index{importing data!XML and HTML files|)}

\section{GPX files}
\index{importing data!GPX files|(}
GPX (GPS Exchange Format) files use an XML scheme designed for saving and exchanging data from geographic positioning systems (GPS). There is some variation on the variables saved depending on the settings of the GPS receiver. The example data used here is from a Transmeta BT747 GPS logger. The example below reads the data into a \code{tibble} as character strings. For plotting, the character values representing numbers and dates would need to be converted to numeric and datetime (\code{POSIXct}) values, respectively. In the case of plotting tracks on a map, it is preferable to use package \pkgname{sf} to import the tracks directly from the \code{.gpx} file into a layer (use of \Rlang pipe operator is described in section \ref{sec:script:pipes} on page \pageref{sec:script:pipes}).

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{xmlTreeParse}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/GPSDATA.gpx"}\hlstd{,} \hlkwc{useInternalNodes} \hlstd{=} \hlnum{TRUE}\hlstd{) |>}
\hlkwd{xmlRoot}\hlstd{(}\hlkwc{x} \hlstd{= _) |>}
\hlkwd{xmlToList}\hlstd{(}\hlkwc{node} \hlstd{= _) |>}
\hlstd{_[[}\hlstr{"trk"}\hlstd{]] |>}
\hlkwd{assign}\hlstd{(}\hlkwc{x} \hlstd{=} \hlstr{"temp"}\hlstd{,} \hlkwc{value} \hlstd{= _) |>}
\hlstd{_[}\hlkwd{names}\hlstd{(}\hlkwc{x} \hlstd{= temp)} \hlopt{==} \hlstr{"trkseg"}\hlstd{] |>}
\hlkwd{unlist}\hlstd{(}\hlkwc{x} \hlstd{= _,} \hlkwc{recursive} \hlstd{=} \hlnum{FALSE}\hlstd{) |>}
\hlkwd{map_df}\hlstd{(}\hlkwc{.x} \hlstd{= _,} \hlkwc{.f} \hlstd{=} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)} \hlkwd{as_tibble}\hlstd{(}\hlkwc{x} \hlstd{=} \hlkwd{t}\hlstd{(}\hlkwc{x} \hlstd{=} \hlkwd{unlist}\hlstd{(}\hlkwc{x} \hlstd{= x))))}
\end{alltt}
\begin{verbatim}
## # A tibble: 199 x 7
##   time                     speed  name         type  fix   .attrs.lat .attrs.lon
##   <chr>                    <chr>  <chr>        <chr> <chr> <chr>      <chr>     
## 1 2018-12-08T23:09:02.000Z 0.0366 trkpt-2018-~ T     3d    -34.912071 138.660595
## 2 2018-12-08T23:09:04.000Z 0.0884 trkpt-2018-~ T     3d    -34.912067 138.660543
## 3 2018-12-08T23:09:06.000Z 0.0147 trkpt-2018-~ T     3d    -34.912102 138.660554
## # i 196 more rows
\end{verbatim}
\begin{alltt}
\hlkwd{rm}\hlstd{(temp)} \hlcom{# cleanup}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{playground}
  To understand what data transformation takes place in each statement of this pipe, start by running the first statement by itself, excluding the pipe operator, and continue adding one statement at a time, and at each step check the returned value and look out for what has changed from the previous step. Optionally you can insert a line \code{print() |>} at the point where you wish to see the data being ``piped''.
\end{playground}

\index{importing data!GPX files|)}

\section{Worksheets}\label{sec:files:worksheets}
\index{importing data!worksheets and workbooks|(}

Microsoft Office, Open Office and Libre Office are the most frequently used suites containing programs based on the worksheet paradigm. There is available a standardized file format for exchange of worksheet data, but it does not support all the features present in native file formats. We will start by considering \pgrmname{MS-Excel}. The file format used by \pgrmname{MS-Excel} has changed significantly over the years, and old formats tend to be less well supported by available \Rlang packages and may require the file to be updated to a more modern format with \pgrmname{MS-Excel} itself before import into \Rlang. The current format is based on XML and relatively simple to decode, whereas older binary formats are more difficult. Worksheets contain code as equations in addition to the actual data. In all cases, only values entered as such or those computed by means of the embedded equations can be imported into \Rlang rather than the equations themselves.

\begin{warningbox}
When directly reading from a worksheet, a column of cells with mixed type, can introduce \code{NA} values. A wrongly selected cell range from the worksheet can result in missing columns or rows, if the area is too small, or in rows or columns filled with \code{NA} values, if the range includes empty cells in the worksheet. Depending on the function used, it may be possible to ignore empty cells, by passing an argument.

Many problems related to the import of data from work sheets and work books are due to translation between two different formats that impose different restrictions on what is allowed or not. While in a worksheet it is allowed to set the ``format'' (as called in \pgrmname{Excel}, and roughly equivalent to \code{mode} in \Rlang) of individual cells, a variable (column) in an \Rlang data frame is expected to be vector, and thus contain members belonging the same \code{mode} or type. For the import to work as expected, the ``format'' must be consistent, i.e., all cells in a column to be imported are marked as one of the \code{Number}, \code{Date}, \code{Time} or \code{Text} formats, with the possible exception of a \emph{single row} of column headers with the names of the variables as \code{Text}. The default format \code{General} also works but as it does not ensure consistency, it makes more difficult to see format inconsistencies at a glance in Excel.

When reading a \code{CSV} file, text representing numbers will be recognized and converted, but only if the decimal point is encoded as expected from the arguments passed to the function call. So a single number with a comma instead of a dot as decimal marker (or vice versa) will result in most cases in the column not being decoded as numbers and returned as a \code{character} vector (or column) in the data frame. In the case of package \pkgname{readr} a \code{numeric} vector containing \code{NA} values for the non-decoded text may be returned instead of a \code{character} vector depending on whether the wrong decimal marker appears near the top or near the end of the file.

When importing data from a worksheet or workbook, my recommendation is first to check it in the original software to ensure that the cells to be imported are encoded as expected. When using a \code{CSV} as an intermediate step, it is crucial to also open this file in a plain-text editor such as the editor pane in \RStudio (or \pgrmname{Notepad} in \pgrmnameNI{Windows} or \pgrmname{Nano}, \pgrmname{Emacs}, etc., in \pgrmnameNI{Unix} and \pgrmnameNI{Linux}). Based on what field separator, decimal mark, and possibly character encoding has been used, which depends on the locale settings in the operating system of the computer and in the worksheet program, select a suitable function to call and the necessary arguments to pass to it.
\end{warningbox}

\subsection{CSV files as middlemen}

If we have access to the original software used for creating a worksheet or workbook, then exporting worksheets to text files in CSV format and importing them into \Rlang using the functions described in sections \ref{sec:files:txt} and \ref{sec:files:readr} starting on pages \pageref{sec:files:txt} and \pageref{sec:files:readr} provides a broadly compatible route for importing data---with the caveat that we should take care that delimiters and decimal marks match the expectations of the functions used. This approach is not ideal from the perspective of having to create intermediate \code{CSV} formatted text files. A better approach is, when feasible, to import the data directly from the workbook or worksheets into \Rlang.

\subsection[`readxl']{\pkgname{readxl}}\label{sec:files:excel}
\index{importing data!.xlsx files|(}



Package \pkgname{readxl} supports reading of \pgrmname{MS-Excel} workbooks, and selecting worksheets and regions within worksheets specified in ways similar to those used by \pgrmname{MS-Excel} itself. The interface is simple, and the package easy to install. We will import a file that in \pgrmname{MS-Excel} looks like the screen capture below.

\begin{center}
\includegraphics[width=0.75\textwidth]{figures/Book1-xlsx.png}
\end{center}

We first list the sheets contained in the workbook file with \Rfunction{excel\_sheets()}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{sheets} \hlkwb{<-} \hlkwd{excel_sheets}\hlstd{(}\hlstr{"extdata/Book1.xlsx"}\hlstd{)}
\hlstd{sheets}
\end{alltt}
\begin{verbatim}
## [1] "my data"
\end{verbatim}
\end{kframe}
\end{knitrout}

In this case, the argument passed to \code{sheet} is redundant, as there is only a single worksheet in the file. It is possible to use either the name of the sheet or a positional index (in this case \code{1} would be equivalent to \code{"my data"}). We use function \Rfunction{read\_excel()} to import the worksheet. Being part of the \pkgname{tidyverse} the returned value is a tibble and character columns are returned as is.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{Book1.df} \hlkwb{<-} \hlkwd{read_excel}\hlstd{(}\hlstr{"extdata/Book1.xlsx"}\hlstd{,}
                       \hlkwc{sheet} \hlstd{=} \hlstr{"my data"}\hlstd{)}
\hlstd{Book1.df}
\end{alltt}
\begin{verbatim}
## # A tibble: 10 x 3
##   sample group observation
##    <dbl> <chr>       <dbl>
## 1      1 a               1
## 2      2 a               5
## 3      3 a               7
## # i 7 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

We can also read a region instead of the whole worksheet.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{Book1_region.df} \hlkwb{<-} \hlkwd{read_excel}\hlstd{(}\hlstr{"extdata/Book1.xlsx"}\hlstd{,}
                              \hlkwc{sheet} \hlstd{=} \hlstr{"my data"}\hlstd{,}
                              \hlkwc{range} \hlstd{=} \hlstr{"A1:B8"}\hlstd{)}
\hlstd{Book1_region.df}
\end{alltt}
\begin{verbatim}
## # A tibble: 7 x 2
##   sample group
##    <dbl> <chr>
## 1      1 a    
## 2      2 a    
## 3      3 a    
## # i 4 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

Of the remaining arguments, the most useful ones have the same names and play similar roles as in \pkgname{readr} (see section \ref{sec:files:readr} on page \pageref{sec:files:readr}). For example, we can set new names to the columns instead of reading their names from the worksheet.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{Book1_region.df} \hlkwb{<-} \hlkwd{read_excel}\hlstd{(}\hlstr{"extdata/Book1.xlsx"}\hlstd{,}
                              \hlkwc{sheet} \hlstd{=} \hlstr{"my data"}\hlstd{,}
                              \hlkwc{range} \hlstd{=} \hlstr{"A2:B8"}\hlstd{,}
                              \hlkwc{col_names} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"A"}\hlstd{,} \hlstr{"B"}\hlstd{))}
\hlstd{Book1_region.df}
\end{alltt}
\begin{verbatim}
## # A tibble: 7 x 2
##       A B    
##   <dbl> <chr>
## 1     1 a    
## 2     2 a    
## 3     3 a    
## # i 4 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

\subsection[`xlsx']{\pkgname{xlsx}}



Package \pkgname{xlsx} can be more difficult to install as it uses Java functions to do the actual work. However, it is more comprehensive, with functions both for reading and writing \pgrmname{MS-Excel} worksheets and workbooks, in different formats including the older binary ones. Similar to \pkgname{readr} it allows selected regions of a worksheet to be imported.

Here we use function \Rfunction{read.xlsx()}, indexing the worksheet by name. The returned value is a data frame, and following the expectations of \Rlang package \pkgnameNI{utils}, character columns are converted into factors by default.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{Book1_xlsx.df} \hlkwb{<-} \hlkwd{read.xlsx}\hlstd{(}\hlstr{"extdata/Book1.xlsx"}\hlstd{,}
                           \hlkwc{sheetName} \hlstd{=} \hlstr{"my data"}\hlstd{)}
\hlstd{Book1_xlsx.df}
\end{alltt}
\begin{verbatim}
##    sample group observation
## 1       1     a         1.0
## 2       2     a         5.0
## 3       3     a         7.0
## 4       4     a         2.0
## 5       5     a         5.0
## 6       6     b         0.0
## 7       7     b         2.0
## 8       8     b         3.0
## 9       9     b         1.0
## 10     10     b         1.5
\end{verbatim}
\end{kframe}
\end{knitrout}

With function \Rfunction{write.xlsx()} we can write data frames out to Excel worksheets and even append new worksheets to an existing workbook.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{set.seed}\hlstd{(}\hlnum{456321}\hlstd{)}
\hlstd{my.data} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{1}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwc{y} \hlstd{= letters[}\hlnum{1}\hlopt{:}\hlnum{10}\hlstd{])}
\hlkwd{write.xlsx}\hlstd{(my.data,}
           \hlkwc{file} \hlstd{=} \hlstr{"extdata/my-data.xlsx"}\hlstd{,}
           \hlkwc{sheetName} \hlstd{=} \hlstr{"first copy"}\hlstd{)}
\hlkwd{write.xlsx}\hlstd{(my.data,}
           \hlkwc{file} \hlstd{=} \hlstr{"extdata/my-data.xlsx"}\hlstd{,}
           \hlkwc{sheetName} \hlstd{=} \hlstr{"second copy"}\hlstd{,}
           \hlkwc{append} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

When opened in Excel, we get a workbook containing two worksheets, named using the arguments we passed through \code{sheetName} in the code chunk above.
% screen capture to be replaced!!
\begin{center}
\includegraphics[width=0.75\textwidth]{figures/my-data-xlsx.png}
\end{center}

\begin{playground}
If you have some worksheet files available, import them into \Rlang to get a feel for how the way in which data is organized in the worksheets affects how easy or difficult it is to import them into \Rlang.
\end{playground}
\index{importing data!.xlsx files|)}

\subsection[`readODS']{\pkgname{readODS}}
\index{importing data!.ods files|(}

Package \pkgname{readODS} provides functions for reading data saved in files that follow the \emph{Open Documents Standard}. Function \Rfunction{read\_ods()} has a similar but simpler user interface to that of \code{read\_excel()} and reads one worksheet at a time, with support only for skipping top rows. The value returned is a data frame.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{ods.df} \hlkwb{<-} \hlkwd{read_ods}\hlstd{(}\hlstr{"extdata/Book1.ods"}\hlstd{,} \hlkwc{sheet} \hlstd{=} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{ods.df}
\end{alltt}
\begin{verbatim}
## # A tibble: 10 x 3
##   sample group observation
##    <dbl> <chr>       <dbl>
## 1      1 a               1
## 2      2 a               5
## 3      3 a               7
## # i 7 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

Function \Rfunction{write\_ods()} writes a data frame into an ODS file.
\index{importing data!.ods files|)}
\index{importing data!worksheets and workbooks|)}

\section{Statistical software}\label{sec:files:stat}
\index{importing data!other statistical software|(}

There are two different comprehensive packages for importing data saved from other statistical programs such as SAS, Statistica, SPSS, etc. The longtime ``standard'' is package \pkgname{foreign} included in base \Rlang, and package \pkgname{haven} is a newer contributed extension. In the case of files saved with old versions of statistical programs, functions from \pkgname{foreign} tend to be more robust than those from \pkgname{haven}.

\subsection[foreign]{\pkgname{foreign}}



Functions in package \pkgname{foreign} allow us to import data from files saved by several statistical analysis programs, including \pgrmname{SAS}, \pgrmname{Stata}, \pgrmname{SPSS}, \pgrmname{Systat}, \pgrmname{Octave} among others, and a function for writing data into files with formats native to \pgrmname{SAS}, \pgrmname{Stata}, and \pgrmname{SPSS}. \Rlang documents the use of these functions in detail in the \emph{R Data Import/Export} manual. As a simple example, we use function \Rfunction{read.spss()} to read a \texttt{.sav} file, saved a few years ago with the then current version of \pgrmname{SPSS}. We display only the first six rows and seven columns of the data frame, including a column with dates, which appears as numeric.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{my_spss.df} \hlkwb{<-} \hlkwd{read.spss}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/my-data.sav"}\hlstd{,} \hlkwc{to.data.frame} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlstd{my_spss.df[}\hlnum{1}\hlopt{:}\hlnum{6}\hlstd{,} \hlkwd{c}\hlstd{(}\hlnum{1}\hlopt{:}\hlnum{6}\hlstd{,} \hlnum{17}\hlstd{)]}
\end{alltt}
\begin{verbatim}
##   block       treat mycotreat water1 pot harvest harvest_date
## 1     0 Watered, EM         1      1  14       1  13653705600
## 2     0 Watered, EM         1      1  52       1  13653705600
## 3     0 Watered, EM         1      1 111       1  13653705600
## 4     0 Watered, EM         1      1 127       1  13653705600
## 5     0 Watered, EM         1      1 230       1  13653705600
## 6     0 Watered, EM         1      1 258       1  13653705600
\end{verbatim}
\end{kframe}
\end{knitrout}

A second example, this time with a simple \code{.sav} file saved 15 years ago.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{thiamin.df} \hlkwb{<-} \hlkwd{read.spss}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/thiamin.sav"}\hlstd{,} \hlkwc{to.data.frame} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlkwd{head}\hlstd{(thiamin.df)}
\end{alltt}
\begin{verbatim}
##   THIAMIN CEREAL
## 1     5.2  wheat
## 2     4.5  wheat
## 3     6.0  wheat
## 4     6.1  wheat
## 5     6.7  wheat
## 6     5.8  wheat
\end{verbatim}
\end{kframe}
\end{knitrout}

Another example, for a \pgrmname{Systat} file saved on an PC more than 20 years ago, and read with \Rfunction{read.systat()}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{my_systat.df} \hlkwb{<-} \hlkwd{read.systat}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/BIRCH1.SYS"}\hlstd{)}
\hlkwd{head}\hlstd{(my_systat.df)}
\end{alltt}
\begin{verbatim}
##   CONT DENS BLOCK SEEDL VITAL BASE ANGLE HEIGHT DIAM
## 1    1    1     1     2    44    2     0      1   53
## 2    1    1     1     2    41    2     1      2   70
## 3    1    1     1     2    21    2     0      1   65
## 4    1    1     1     2    15    3     0      1   79
## 5    1    1     1     2    37    3     0      1   71
## 6    1    1     1     2    29    2     1      1   43
\end{verbatim}
\end{kframe}
\end{knitrout}

Not all functions in \pkgname{foreign} return data frames by default, but all of them can be coerced to do so.

\subsection[haven]{\pkgname{haven}}



Package \pkgname{haven} is less ambitious with respect to the number of formats supported, or their vintages, providing read and write functions for only three file formats: \pgrmname{SAS}, \pgrmname{Stata} and \pgrmname{SPSS}. On the other hand, \pkgname{haven} provides flexible ways to convert the different labeled values that cannot be directly mapped to \Rlang modes. They also decode dates and times according to the idiosyncrasies of each of these file formats. In cases when the imported file contains labeled values the returned \Rclass{tibble} object needs some additional attention from the user. Labeled numeric columns in \pgrmname{SPSS} are not necessarily equivalent to factors, although they sometimes are. Consequently, conversion to factors cannot be automated and must be done manually in a separate step.

We can use function \Rfunction{read\_sav()} to import a \code{.sav} file saved by a recent version of \pgrmname{SPSS}. As in the previous section, we display only the first six rows and seven columns of the data frame, including a column \code{treat} containing a labeled numeric vector and \code{harvest\_date} with dates encoded as \Rlang date values.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{my_spss.tb} \hlkwb{<-} \hlkwd{read_sav}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/my-data.sav"}\hlstd{)}
\hlstd{my_spss.tb[}\hlnum{1}\hlopt{:}\hlnum{6}\hlstd{,} \hlkwd{c}\hlstd{(}\hlnum{1}\hlopt{:}\hlnum{6}\hlstd{,} \hlnum{17}\hlstd{)]}
\end{alltt}
\begin{verbatim}
## # A tibble: 6 x 7
##   block treat           mycotreat water1   pot harvest harvest_date
##   <dbl> <dbl+lbl>           <dbl>  <dbl> <dbl>   <dbl> <date>      
## 1     0 1 [Watered, EM]         1      1    14       1 2015-06-15  
## 2     0 1 [Watered, EM]         1      1    52       1 2015-06-15  
## 3     0 1 [Watered, EM]         1      1   111       1 2015-06-15  
## # i 3 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

In this case, the dates are correctly decoded.

Next, we import an \pgrmname{SPSS}'s \code{.sav} file saved 15 years ago.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{thiamin.tb} \hlkwb{<-} \hlkwd{read_sav}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"extdata/thiamin.sav"}\hlstd{)}
\hlstd{thiamin.tb}
\end{alltt}
\begin{verbatim}
## # A tibble: 24 x 2
##   THIAMIN CEREAL   
##     <dbl> <dbl+lbl>
## 1     5.2 1 [wheat]
## 2     4.5 1 [wheat]
## 3     6   1 [wheat]
## # i 21 more rows
\end{verbatim}
\begin{alltt}
\hlstd{thiamin.tb} \hlkwb{<-} \hlkwd{as_factor}\hlstd{(thiamin.tb)}
\hlstd{thiamin.tb}
\end{alltt}
\begin{verbatim}
## # A tibble: 24 x 2
##   THIAMIN CEREAL
##     <dbl> <fct> 
## 1     5.2 wheat 
## 2     4.5 wheat 
## 3     6   wheat 
## # i 21 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{playground}
Compare the values returned by different \code{read} functions when applied to the same file on disk. Use \Rfunction{names()}, \Rfunction{str()} and \Rfunction{class()} as tools in your exploration. If you are brave, also use \Rfunction{attributes()}, \Rfunction{mode()}, \Rfunction{dim()}, \Rfunction{dimnames()}, \Rfunction{nrow()} and \Rfunction{ncol()}.
\end{playground}

\begin{playground}
If you use or have in the past used other statistical software or a general-purpose language like \langname{Python}, look for some old files and import them into \Rlang.
\end{playground}
\index{importing data!other statistical software|)}

\section{NetCDF files}
\index{importing data!NeCDF files|(}

In some fields, including geophysics and meteorology, \pgrmname{NetCDF} is a very common format for the exchange of data. It is also used in other contexts in which data is referenced to a grid of locations, like with data read from Affymetrix microarrays used to study gene expression. \pgrmname{NetCDF} files are binary but use a format that allows the storage of metadata describing each variable together with the data itself in a well-organized and standardized format, which is ideal for exchange of moderately large data sets measured on a spatial or spatio-temporal grid.

Officially described as follows:
\begin{quote}
\pgrmname{NetCDF} is a set of software libraries [from Unidata] and self-describing, machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.
\end{quote}

As sometimes \pgrmname{NetCDF} files are large, it is good that it is possible to selectively read the data from individual variables with functions in packages \pkgname{ncdf4} or \pkgname{RNetCDF}. On the other hand, this implies that contrary to other data file reading operations, reading a \pgrmname{NetCDF} file is done in two or more steps---i.e., opening the file, reading metadata describing the variables and spatial grid, and finally reading the data of interest.

\subsection[ncdf4]{\pkgname{ncdf4}}



Package \pkgname{ncdf4} supports reading of files using \pgrmname{NetCDF} version 4 or earlier formats. Functions in \pkgname{ncdf4} not only allow reading and writing of these files, but also their modification.

We first read metadata to obtain an index of the file contents, and in additional steps, read a subset of the data. With \Rfunction{print()} we can find out the names and characteristics of the variables and attributes. In this example, we read long-term averages for potential evapotranspiration (PET).

We first open a connection to the file with function \Rfunction{nc\_open()}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{meteo_data.nc} \hlkwb{<-} \hlkwd{nc_open}\hlstd{(}\hlstr{"extdata/pevpr.sfc.mon.ltm.nc"}\hlstd{)}
\hlkwd{str}\hlstd{(meteo_data.nc,} \hlkwc{max.level} \hlstd{=} \hlnum{1}\hlstd{)}
\end{alltt}
\begin{verbatim}
## List of 15
##  $ filename   : chr "extdata/pevpr.sfc.mon.ltm.nc"
##  $ writable   : logi FALSE
##  $ id         : int 65536
##  $ error      : logi FALSE
##  $ safemode   : logi FALSE
##  $ format     : chr "NC_FORMAT_NETCDF4_CLASSIC"
##  $ is_GMT     : logi FALSE
##  $ groups     :List of 1
##  $ fqgn2Rindex:List of 1
##  $ ndims      : num 4
##  $ natts      : num 8
##  $ dim        :List of 4
##  $ unlimdimid : num -1
##  $ nvars      : num 3
##  $ var        :List of 3
##  - attr(*, "class")= chr "ncdf4"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{advplayground}
Increase \code{max.level} in the call to \Rfunction{str()} above and study the connection object stores information on the dimensions and for each data variable. You can also \code{print(meteo\_data.nc)} for a more complete printout once you have understood the structure of the object.
\end{advplayground}

The dimensions of the array data are described with metadata, in our examples mapping indexes to a grid of latitudes and longitudes and into a time vector as a third dimension. The dates are returned as character strings. We get here the variables one at a time with function \Rfunction{ncvar\_get()}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{time.vec} \hlkwb{<-} \hlkwd{ncvar_get}\hlstd{(meteo_data.nc,} \hlstr{"time"}\hlstd{)}
\hlkwd{head}\hlstd{(time.vec)}
\end{alltt}
\begin{verbatim}
## [1] -657073 -657042 -657014 -656983 -656953 -656922
\end{verbatim}
\begin{alltt}
\hlstd{longitude} \hlkwb{<-}  \hlkwd{ncvar_get}\hlstd{(meteo_data.nc,} \hlstr{"lon"}\hlstd{)}
\hlkwd{head}\hlstd{(longitude)}
\end{alltt}
\begin{verbatim}
## [1] 0.000 1.875 3.750 5.625 7.500 9.375
\end{verbatim}
\begin{alltt}
\hlstd{latitude} \hlkwb{<-} \hlkwd{ncvar_get}\hlstd{(meteo_data.nc,} \hlstr{"lat"}\hlstd{)}
\hlkwd{head}\hlstd{(latitude)}
\end{alltt}
\begin{verbatim}
## [1] 88.5420 86.6531 84.7532 82.8508 80.9473 79.0435
\end{verbatim}
\end{kframe}
\end{knitrout}

The \code{time} vector is rather odd, as it contains only monthly data as these are long-term averages, but expressed as days from 1800-01-01 corresponding to the first day of each month of year 1. We use package \pkgname{lubridate} for the conversion.

We construct a \Rclass{tibble} object with PET values for one grid point, taking advantage of the \emph{recycling} of short vectors.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{pet.tb} \hlkwb{<-}
    \hlkwd{tibble}\hlstd{(}\hlkwc{time} \hlstd{=} \hlkwd{ncvar_get}\hlstd{(meteo_data.nc,} \hlstr{"time"}\hlstd{),}
           \hlkwc{month} \hlstd{=} \hlkwd{month}\hlstd{(}\hlkwd{ymd}\hlstd{(}\hlstr{"1800-01-01"}\hlstd{)} \hlopt{+} \hlkwd{days}\hlstd{(time)),}
           \hlkwc{lon} \hlstd{= longitude[}\hlnum{6}\hlstd{],}
           \hlkwc{lat} \hlstd{= latitude[}\hlnum{2}\hlstd{],}
           \hlkwc{pet} \hlstd{=} \hlkwd{ncvar_get}\hlstd{(meteo_data.nc,} \hlstr{"pevpr"}\hlstd{)[}\hlnum{6}\hlstd{,} \hlnum{2}\hlstd{, ]}
           \hlstd{)}
\hlstd{pet.tb}
\end{alltt}
\begin{verbatim}
## # A tibble: 12 x 5
##        time month   lon   lat   pet
##   <dbl[1d]> <dbl> <dbl> <dbl> <dbl>
## 1   -657073    12  9.38  86.7  4.28
## 2   -657042     1  9.38  86.7  5.72
## 3   -657014     2  9.38  86.7  4.38
## # i 9 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

If we want to read in several grid points, we can use several different approaches. However, the order of nesting of dimensions can make adding the dimensions as columns error prone. It is much simpler to use package \pkgnameNI{tidync} described next.

\subsection[tidync]{\pkgname{tidync}}



Package \pkgname{tidync} provides functions that make it easier to extract subsets of the data from an \pgrmname{NetCDF} file. We start by doing the same operations as in the examples for \pkgnameNI{ncdf4}.

We open the file creating an object and simultaneously activating the first grid.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{meteo_data.tnc} \hlkwb{<-} \hlkwd{tidync}\hlstd{(}\hlstr{"extdata/pevpr.sfc.mon.ltm.nc"}\hlstd{)}
\hlstd{meteo_data.tnc}
\end{alltt}
\begin{verbatim}
## 
## Data Source (1): pevpr.sfc.mon.ltm.nc ...
## 
## Grids (5) <dimension family> : <associated variables> 
## 
## [1]   D0,D1,D2 : pevpr, valid_yr_count    **ACTIVE GRID** ( 216576  values per variable)
## [2]   D3,D2    : climatology_bounds
## [3]   D0       : lon
## [4]   D1       : lat
## [5]   D2       : time
## 
## Dimensions 4 (3 active): 
##   
##   dim   name  length     min     max start count    dmin    dmax unlim coord_dim 
##   <chr> <chr>  <dbl>   <dbl>   <dbl> <int> <int>   <dbl>   <dbl> <lgl> <lgl>     
## 1 D0    lon      192  0       3.58e2     1   192  0       3.58e2 FALSE TRUE      
## 2 D1    lat       94 -8.85e1  8.85e1     1    94 -8.85e1  8.85e1 FALSE TRUE      
## 3 D2    time      12 -6.57e5 -6.57e5     1    12 -6.57e5 -6.57e5 FALSE TRUE      
##   
## Inactive dimensions:
##   
##   dim   name  length   min   max unlim coord_dim 
##   <chr> <chr>  <dbl> <dbl> <dbl> <lgl> <lgl>     
## 1 D3    nbnds      2     1     2 FALSE FALSE
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{hyper_dims}\hlstd{(meteo_data.tnc)}
\end{alltt}
\begin{verbatim}
## # A tibble: 3 x 7
##   name  length start count    id unlim coord_dim
##   <chr>  <dbl> <int> <int> <int> <lgl> <lgl>    
## 1 lon      192     1   192     0 FALSE TRUE     
## 2 lat       94     1    94     1 FALSE TRUE     
## 3 time      12     1    12     2 FALSE TRUE
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{hyper_vars}\hlstd{(meteo_data.tnc)}
\end{alltt}
\begin{verbatim}
## # A tibble: 2 x 6
##      id name           type     ndims natts dim_coord
##   <int> <chr>          <chr>    <int> <int> <lgl>    
## 1     4 pevpr          NC_FLOAT     3    14 FALSE    
## 2     5 valid_yr_count NC_FLOAT     3     4 FALSE
\end{verbatim}
\end{kframe}
\end{knitrout}

We extract a subset of the data into a tibble in long (or tidy) format, and add
the months using the pipe operator (\code{|>}) and methods from \pkgname{dplyr}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{hyper_tibble}\hlstd{(meteo_data.tnc,}
             \hlkwc{lon} \hlstd{=} \hlkwd{signif}\hlstd{(lon,} \hlnum{1}\hlstd{)} \hlopt{==} \hlnum{9}\hlstd{,}
             \hlkwc{lat} \hlstd{=} \hlkwd{signif}\hlstd{(lat,} \hlnum{2}\hlstd{)} \hlopt{==} \hlnum{87}\hlstd{) |>}
  \hlkwd{mutate}\hlstd{(}\hlkwc{.data} \hlstd{= _,} \hlkwc{month} \hlstd{=} \hlkwd{month}\hlstd{(}\hlkwd{ymd}\hlstd{(}\hlstr{"1800-01-01"}\hlstd{)} \hlopt{+} \hlkwd{days}\hlstd{(time))) |>}
  \hlkwd{select}\hlstd{(}\hlkwc{.data} \hlstd{= _,} \hlopt{-}\hlstd{time)}
\end{alltt}
\begin{verbatim}
## # A tibble: 12 x 5
##   pevpr valid_yr_count   lon   lat month
##   <dbl>          <dbl> <dbl> <dbl> <dbl>
## 1  4.28       1.19e-39  9.38  86.7    12
## 2  5.72       1.19e-39  9.38  86.7     1
## 3  4.38       1.29e-39  9.38  86.7     2
## # i 9 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

In this second example, we extract data for all grid points along latitudes. To achieve this we need only to omit the test for \code{lat} from the chunk above. The tibble is assembled automatically and columns for the active dimensions added. The decoding of the months remains unchanged.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{hyper_tibble}\hlstd{(meteo_data.tnc,}
             \hlkwc{lon} \hlstd{=} \hlkwd{signif}\hlstd{(lon,} \hlnum{1}\hlstd{)} \hlopt{==} \hlnum{9}\hlstd{) |>}
  \hlkwd{mutate}\hlstd{(}\hlkwc{.data} \hlstd{= _,} \hlkwc{month} \hlstd{=} \hlkwd{month}\hlstd{(}\hlkwd{ymd}\hlstd{(}\hlstr{"1800-01-01"}\hlstd{)} \hlopt{+} \hlkwd{days}\hlstd{(time))) |>}
  \hlkwd{select}\hlstd{(}\hlkwc{.data} \hlstd{= _,} \hlopt{-}\hlstd{time)}
\end{alltt}
\begin{verbatim}
## # A tibble: 1,128 x 5
##   pevpr valid_yr_count   lon   lat month
##   <dbl>          <dbl> <dbl> <dbl> <dbl>
## 1  1.02       1.19e-39  9.38  88.5    12
## 2  4.28       1.19e-39  9.38  86.7    12
## 3  3.03       9.18e-40  9.38  84.8    12
## # i 1,125 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{playground}
Instead of extracting data for one longitude across latitudes, extract data across longitudes for one latitude near the Equator.
\end{playground}
\index{importing data!NeCDF files|)}

\section{Remotely located data}\label{sec:files:remote}
\index{importing data!remote connections|(}

Many of the functions described above accept an URL address in place of a file name. Consequently files can be read remotely without having to first download and save a copy in the local file system. This can be useful, especially when file names are generated within a script. However, one should avoid, especially in the case of servers open to public access, repeatedly downloading the same file as this unnecessarily increases network traffic and workload on the remote server. Because of this, our first example reads a small file from my own web site. See section \ref{sec:files:txt} on page \pageref{sec:files:txt} for details on the use of these and other functions for reading text files.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{logger.df} \hlkwb{<-}
      \hlkwd{read.csv2}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"http://r4photobiology.info/learnr/logger_1.txt"}\hlstd{,}
                \hlkwc{header} \hlstd{=} \hlnum{FALSE}\hlstd{,}
                \hlkwc{col.names} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"time"}\hlstd{,} \hlstr{"temperature"}\hlstd{))}
\hlkwd{sapply}\hlstd{(logger.df, class)}
\end{alltt}
\begin{verbatim}
##        time temperature 
## "character"   "numeric"
\end{verbatim}
\begin{alltt}
\hlkwd{sapply}\hlstd{(logger.df, mode)}
\end{alltt}
\begin{verbatim}
##        time temperature 
## "character"   "numeric"
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{logger.tb} \hlkwb{<-}
    \hlkwd{read_csv2}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"http://r4photobiology.info/learnr/logger_1.txt"}\hlstd{,}
              \hlkwc{col_names} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"time"}\hlstd{,} \hlstr{"temperature"}\hlstd{))}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# i Using "{}','"{} as decimal and "{}'.'"{} as grouping mark. Use `read\_delim()` for more control.}}

{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Rows: 723 Columns: 2\\\#\# -- Column specification --------------------------------------------------------\\\#\# Delimiter: "{};"{}\\\#\# chr (1): time\\\#\# dbl (1): temperature\\\#\# \\\#\# i Use `spec()` to retrieve the full column specification for this data.\\\#\# i Specify the column types or set `show\_col\_types = FALSE` to quiet this message.}}\begin{alltt}
\hlkwd{sapply}\hlstd{(logger.tb, class)}
\end{alltt}
\begin{verbatim}
##        time temperature 
## "character"   "numeric"
\end{verbatim}
\begin{alltt}
\hlkwd{sapply}\hlstd{(logger.tb, mode)}
\end{alltt}
\begin{verbatim}
##        time temperature 
## "character"   "numeric"
\end{verbatim}
\end{kframe}
\end{knitrout}

While functions in package \pkgname{readr} support the use of URLs, those in packages \pkgname{readxl} and \pkgname{xlsx} do not. Consequently, we need to first download the file and save a copy locally, that we can read as described in section \ref{sec:files:excel} on page \pageref{sec:files:excel}. Function \Rfunction{download.file()} in the \Rlang \pkgname{utils} package can be used to download files using URLs. It supports different modes such as binary or text, and write or append, and different methods such as \code{"internal"}, \code{"wget"} and \code{"libcurl" }.

\begin{warningbox}
For portability, \pgrmname{MS-Excel} files should be downloaded in binary mode, setting \code{mode = "wb"}, which is required under \osname{MS-Windows}.
\end{warningbox}


\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{download.file}\hlstd{(}\hlstr{"http://r4photobiology.info/learnr/my-data.xlsx"}\hlstd{,}
              \hlstr{"data/my-data-dwn.xlsx"}\hlstd{,}
              \hlkwc{mode} \hlstd{=} \hlstr{"wb"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

Functions in package \pkgname{foreign}, as well as those in package \pkgname{haven}, support URLs. See section \ref{sec:files:stat} on page \pageref{sec:files:stat} for more information about importing this kind of data into \Rlang.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{remote_thiamin.df} \hlkwb{<-}
  \hlkwd{read.spss}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"http://r4photobiology.info/learnr/thiamin.sav"}\hlstd{,}
            \hlkwc{to.data.frame} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlkwd{head}\hlstd{(remote_thiamin.df)}
\end{alltt}
\begin{verbatim}
##   THIAMIN CEREAL
## 1     5.2  wheat
## 2     4.5  wheat
## 3     6.0  wheat
## 4     6.1  wheat
## 5     6.7  wheat
## 6     5.8  wheat
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{remote_my_spss.tb} \hlkwb{<-}
    \hlkwd{read_sav}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"http://r4photobiology.info/learnr/thiamin.sav"}\hlstd{)}
\hlstd{remote_my_spss.tb}
\end{alltt}
\begin{verbatim}
## # A tibble: 24 x 2
##   THIAMIN CEREAL   
##     <dbl> <dbl+lbl>
## 1     5.2 1 [wheat]
## 2     4.5 1 [wheat]
## 3     6   1 [wheat]
## # i 21 more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

In this example we use a downloaded NetCDF file of long-term means for potential evapotranspiration from NOOA, the same used above in the \pkgname{ncdf4} example. This is a moderately large file at 444~KB. In this case, we cannot directly open the connection to the NetCDF file, and we first download it (commented out code, as we have a local copy), and then we open the local file.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{my.url} \hlkwb{<-} \hlkwd{paste}\hlstd{(}\hlstr{"ftp://ftp.cdc.noaa.gov/Datasets/ncep.reanalysis.derived/"}\hlstd{,}
                \hlstr{"surface_gauss/pevpr.sfc.mon.ltm.nc"}\hlstd{,}
                \hlkwc{sep} \hlstd{=} \hlstr{""}\hlstd{)}
\hlcom{#download.file(my.url,}
\hlcom{#              mode = "wb",}
\hlcom{#              destfile = "extdata/pevpr.sfc.mon.ltm.nc")}
\hlstd{pet_ltm.nc} \hlkwb{<-} \hlkwd{nc_open}\hlstd{(}\hlstr{"extdata/pevpr.sfc.mon.ltm.nc"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{warningbox}
For portability, \pgrmname{NetCDF} files should be downloaded in binary mode, setting \code{mode = "wb"}, which is required under \osname{MS-Windows}.
\end{warningbox}
\index{importing data!remote connections|)}

\section{Data acquisition from physical devices}\label{sec:data:acquisition}
\index{importing data!physical devices|(}

Numerous\index{internet-of-things} modern data acquisition devices based on microcontrollers, including internet-of-things (IoT) devices, have servers (or daemons) that can be queried over a network connection to retrieve either real-time or logged data. Formats based on XML schemas or in JSON format are commonly used.

\subsection[jsonlite]{\pkgname{jsonlite}}



\index{importing data!jsonlite}\index{YoctoPuce modules}
We give here a simple example using a module from the \href{http://www.yoctopuce.com/}{YoctoPuce} family using a software hub running locally. We retrieve logged data from a YoctoMeteo module.

\begin{warningbox}
This example needs setting the configuration of the YoctoPuce module beforehand. Fully reproducible examples, including configuration instructions, will be provided online.
\end{warningbox}

Here we use function \Rfunction{fromJSON()} from package \pkgname{jsonlite} to retrieve logged data from one sensor.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{hub.url} \hlkwb{<-} \hlstr{"http://localhost:4444/"}
\hlstd{Meteo01.df} \hlkwb{<-}
    \hlkwd{fromJSON}\hlstd{(}\hlkwd{paste}\hlstd{(hub.url,} \hlstr{"byName/METEO01/dataLogger.json"}\hlstd{,}
                   \hlkwc{sep} \hlstd{=} \hlstr{""}\hlstd{),} \hlkwc{flatten} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlkwd{str}\hlstd{(Meteo01.df,} \hlkwc{max.level} \hlstd{=} \hlnum{2}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

The minimum, mean, and maximum values for each logging interval need to be split from a single vector. We do this by indexing with a logical vector (recycled). The data returned is in long form, with quantity names and units also returned by the module, as well as the time.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{Meteo01.df[[}\hlstr{"streams"}\hlstd{]][[}\hlkwd{which}\hlstd{(Meteo01.df}\hlopt{$}\hlstd{id} \hlopt{==} \hlstr{"temperature"}\hlstd{)]] |>}
  \hlkwd{as_tibble}\hlstd{(}\hlkwc{x} \hlstd{= _) |>}
  \hlstd{dplyr}\hlopt{::}\hlkwd{transmute}\hlstd{(}\hlkwc{.data} \hlstd{= _,}
                   \hlkwc{utc.time} \hlstd{=} \hlkwd{as.POSIXct}\hlstd{(utc,} \hlkwc{origin} \hlstd{=} \hlstr{"1970-01-01"}\hlstd{,} \hlkwc{tz} \hlstd{=} \hlstr{"UTC"}\hlstd{),}
                   \hlkwc{t_min} \hlstd{=} \hlkwd{unlist}\hlstd{(val)[}\hlkwd{c}\hlstd{(}\hlnum{TRUE}\hlstd{,} \hlnum{FALSE}\hlstd{,} \hlnum{FALSE}\hlstd{)],}
                   \hlkwc{t_mean} \hlstd{=} \hlkwd{unlist}\hlstd{(val)[}\hlkwd{c}\hlstd{(}\hlnum{FALSE}\hlstd{,} \hlnum{TRUE}\hlstd{,} \hlnum{FALSE}\hlstd{)],}
                   \hlkwc{t_max} \hlstd{=} \hlkwd{unlist}\hlstd{(val)[}\hlkwd{c}\hlstd{(}\hlnum{FALSE}\hlstd{,} \hlnum{FALSE}\hlstd{,} \hlnum{TRUE}\hlstd{)])} \hlkwb{->} \hlstd{temperature.df}

\hlstd{Meteo01.df[[}\hlstr{"streams"}\hlstd{]][[}\hlkwd{which}\hlstd{(Meteo01.df}\hlopt{$}\hlstd{id} \hlopt{==} \hlstr{"humidity"}\hlstd{)]] |>}
  \hlkwd{as_tibble}\hlstd{(}\hlkwc{x} \hlstd{= _) |>}
  \hlstd{dplyr}\hlopt{::}\hlkwd{transmute}\hlstd{(}\hlkwc{.data} \hlstd{= _,}
                   \hlkwc{utc.time} \hlstd{=} \hlkwd{as.POSIXct}\hlstd{(utc,} \hlkwc{origin} \hlstd{=} \hlstr{"1970-01-01"}\hlstd{,} \hlkwc{tz} \hlstd{=} \hlstr{"UTC"}\hlstd{),}
                   \hlkwc{hr_min} \hlstd{=} \hlkwd{unlist}\hlstd{(val)[}\hlkwd{c}\hlstd{(}\hlnum{TRUE}\hlstd{,} \hlnum{FALSE}\hlstd{,} \hlnum{FALSE}\hlstd{)],}
                   \hlkwc{hr_mean} \hlstd{=} \hlkwd{unlist}\hlstd{(val)[}\hlkwd{c}\hlstd{(}\hlnum{FALSE}\hlstd{,} \hlnum{TRUE}\hlstd{,} \hlnum{FALSE}\hlstd{)],}
                   \hlkwc{hr_max} \hlstd{=} \hlkwd{unlist}\hlstd{(val)[}\hlkwd{c}\hlstd{(}\hlnum{FALSE}\hlstd{,} \hlnum{FALSE}\hlstd{,} \hlnum{TRUE}\hlstd{)])} \hlkwb{->} \hlstd{humidity.df}

\hlkwd{full_join}\hlstd{(temperature.df, humidity.df)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{explainbox}
Most YoctoPuce input modules have a built-in datalogger, and the stored data can also be downloaded as a \code{CSV} file through a physical or virtual hub. As shown above, it is possible to control them through the HTML server in the physical or virtual hubs. Alternatively the \Rlang package \pkgname{reticulate} can be used to control YoctoPuce modules by means of the \langname{Python} library giving access to their API.
\end{explainbox}
\index{importing data!physical devices|)}

\section{Databases}\label{sec:data:db}
\index{importing data!databases|(}






One of the advantages of using databases is that subsets of cases and variables can be retrieved, even remotely, making it possible to work in \Rlang both locally and remotely with huge data sets. One should remember that \Rlang natively keeps whole objects in RAM, and consequently, available machine memory limits the size of data sets with which it is possible to work. Package \pkgname{dbplyr} provides the tools to work with data in databases using the same verbs as when using \pkgname{dplyr} with data stored in memory (RAM) (see chapter \ref{chap:R:data}). This is an important subject, but extensive enough to be outside the scope of this book. We provide a few simple examples to show the very basics but interested readers should consult \citebooktitle{Wickham2017} \autocite{Wickham2017}.

The additional steps compared to using \pkgname{dplyr} start with the need to establish a connection to a local or remote database. We will use \Rlang package \pkgname{RSQLite} to create a local temporary \pgrmname{SQLite} database. \pkgname{dbplyr} backends supporting other database systems are also available. We will use meteorological data from \pkgname{learnrbook} for this example.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(dplyr)}
\hlstd{con} \hlkwb{<-} \hlstd{DBI}\hlopt{::}\hlkwd{dbConnect}\hlstd{(RSQLite}\hlopt{::}\hlkwd{SQLite}\hlstd{(),} \hlkwc{dbname} \hlstd{=} \hlstr{":memory:"}\hlstd{)}
\hlkwd{copy_to}\hlstd{(con, weather_wk_25_2019.tb,} \hlstr{"weather"}\hlstd{,}
        \hlkwc{temporary} \hlstd{=} \hlnum{FALSE}\hlstd{,}
        \hlkwc{indexes} \hlstd{=} \hlkwd{list}\hlstd{(}
          \hlkwd{c}\hlstd{(}\hlstr{"month_name"}\hlstd{,} \hlstr{"calendar_year"}\hlstd{,} \hlstr{"solar_time"}\hlstd{),}
          \hlstr{"time"}\hlstd{,}
          \hlstr{"sun_elevation"}\hlstd{,}
          \hlstr{"was_sunny"}\hlstd{,}
          \hlstr{"day_of_year"}\hlstd{,}
          \hlstr{"month_of_year"}
        \hlstd{)}
\hlstd{)}
\hlstd{weather.db} \hlkwb{<-} \hlkwd{tbl}\hlstd{(con,} \hlstr{"weather"}\hlstd{)}
\hlkwd{colnames}\hlstd{(weather.db)}
\end{alltt}
\begin{verbatim}
##  [1] "time"           "PAR_umol"       "PAR_diff_fr"    "global_watt"   
##  [5] "day_of_year"    "month_of_year"  "month_name"     "calendar_year" 
##  [9] "solar_time"     "sun_elevation"  "sun_azimuth"    "was_sunny"     
## [13] "wind_speed"     "wind_direction" "air_temp_C"     "air_RH"        
## [17] "air_DP"         "air_pressure"   "red_umol"       "far_red_umol"  
## [21] "red_far_red"
\end{verbatim}
\begin{alltt}
\hlstd{weather.db |>}
  \hlkwd{filter}\hlstd{(}\hlkwc{.data} \hlstd{= _, sun_elevation} \hlopt{>} \hlnum{5}\hlstd{) |>}
  \hlkwd{group_by}\hlstd{(}\hlkwc{.data} \hlstd{= _, day_of_year) |>}
  \hlkwd{summarise}\hlstd{(}\hlkwc{.data} \hlstd{= _,} \hlkwc{energy_Wh} \hlstd{=} \hlkwd{sum}\hlstd{(global_watt,} \hlkwc{na.rm} \hlstd{=} \hlnum{TRUE}\hlstd{)} \hlopt{*} \hlnum{60} \hlopt{/} \hlnum{3600}\hlstd{)}
\end{alltt}
\begin{verbatim}
## # Source:   SQL [?? x 2]
## # Database: sqlite 3.41.2 [:memory:]
##   day_of_year energy_Wh
##         <dbl>     <dbl>
## 1         162     7500.
## 2         163     6660.
## 3         164     3958.
## # i more rows
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{explainbox}
Package \pkgname{dbplyr} translates data pipes that use \pkgname{dplyr} syntax into SQL queries to databases, either local or remote. As long as there are no problems with the backend, the use of a database is almost transparent to the \Rlang user.
\end{explainbox}
\index{importing data!databases|)}

\begin{explainbox}
It is always good to clean up, and in the case of the book, the best way to test that the examples
can be run in a ``clean'' system.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{unlink}\hlstd{(}\hlstr{"./data"}\hlstd{,} \hlkwc{recursive} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlkwd{unlink}\hlstd{(}\hlstr{"./extdata"}\hlstd{,} \hlkwc{recursive} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{explainbox}

\section{Further reading}
Since\index{further reading!elegant R code}\index{further reading!idiosyncracies or R} this is the end of the book, I recommend as further reading the writings of \citeauthor{Burns1998} as they are full of insight. Having arrived at the end of \emph{Learn R: As a Language} you should read \citebooktitle{Burns1998} \autocite{Burns1998} and \citebooktitle{Burns2012} \autocite{Burns2012}. If you want to never get caught unaware by \Rlang's idiosyncrasies, read also \citebooktitle{Burns2011} \autocite{Burns2011}.





\backmatter

\printbibliography

\printindex\label{idx:general}

\printindex[rindex]\label{idx:rindex}

\indexprologue{\noindent\Rlang names and symbols grouped into the categories `classes and modes', `constant and special values', 
`control of execution', `data objects', `functions and methods', `names and their scope', and `operators'.} 
\printindex[rcatsidx]\label{idx:rcats}

\indexprologue{Frequently asked questions and their answers appear in the body of the book preceded by the icon \faqicon 
and highlighted by a marginal bar of the same colour as the icon.}
\printindex[faqindex]\label{idx:faqindex}

\end{document}

\appendix

\chapter{Build information}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{Sys.info}\hlstd{()}
\end{alltt}
\end{kframe}
\end{knitrout}



\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.984, 0.984, 0.984}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{sessionInfo}\hlstd{()}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{document}


