% !Rnw root = appendix.main.Rnw

<<echo=FALSE, include=FALSE>>=
opts_chunk$set(opts_fig_wide)
opts_knit$set(concordance=TRUE)
opts_knit$set(unnamed.chunk.label = 'data-chunk')
@

\chapter{R Extensions: Data Wrangling}\label{chap:R:data}

\begin{VF}
Essentially everything in S[R], for instance, a call to a function, is an S[R] object. One viewpoint is that S[R] has self-knowledge. This self-awareness makes a lot of things possible in S[R] that are not in other languages.

\VA{Patrick J. Burns}{\emph{S Poetry}, 1998}\nocite{Burns1998}
\end{VF}

\section{Aims of this chapter}

Base \Rlang and the recommended extension packages (installed by default) include many functions for manipulating data. The \Rlang distribution supplies a complete set of functions and operators that allow all the usual data manipulation operations. These functions have stable and well-described behavior, so in my view they should be preferred unless some of their limitations justify the use of alternatives defined in contributed packages. In the present chapter I describe the new syntax introduced by the most popular contributed \Rlang extension packages aiming at changing (usually improving one aspect at the expense of another) in various ways how we can manipulate data in \Rlang. These independently developed packages extend the \Rlang language not only by adding new ``words'' to it but by supporting new ways of meaningfully connecting ``words''---i.e., providing new ``grammars'' for data manipulation. While at the current stage of development of base \Rlang not breaking existing code has been the priority, several of the still ``young'' packages in the \pkgname{tidyverse} have prioritized experimentation with enhanced features over backwards compatibility. The development of \pkgname{tidyverse} packages seems to have emphasized users' convenience more than encouraging safe/error-free user code. The design of package \pkgname{data.table} has prioritized performance at the expense of easy of use. I do not describe in depth these new approaches but instead only briefly compare them to base \Rlang highlighting the most important differences.

\section{Introduction}

By reading previous chapters, you have already become familiar with base \Rlang classes, methods, functions and operators for storing and manipulating data. Most of these had been originally designed to perform optimally on rather small data sets \autocite[see][]{Matloff2011}. The \Rlang implementation has been improved over the years significantly in performance, and random-access memory in computers has become cheaper, making constraints imposed by the original design of \Rpgrm less limiting. On the other hand, the size of data sets has also increased.

Some contributed packages have aimed at improving performance by relying on different compromises between usability, speed and reliability than used for base \Rlang.
Package \pkgname{data.table} is the best example of an alternative implementation of data storage and manipulation that maximizes the speed of processing for large data sets using a new semantics and requiring a new syntax. We could say that package \pkgname{data.table} is based on a theoretical abstraction, or ``grammar of data'', that is different from that in the \Rlang language. The compromise in this case has been the use of a less intuitive syntax, and by defaulting to passing arguments by reference instead of by copy, increasing the ``responsibility'' of the programmer or data analyst with respect to not overwriting or corrupting data. This focus on performance has made obvious performance bottlenecks in base \Rpgrm which have been subsequently alleviated while maintaining backwards compatibility for users' code.

Another recent development is the \pkgname{tidyverse}, which is a formidable effort to redefine how data analysis operations are expressed in \Rlang code and scripts. In many ways it is also a new abstraction, or ``grammar of data''. With respect to its implementation, it can also be seen as a new language built on-top of the \Rlang language. It is still young and evolving, and the developers from Posit still remain relentless about fixing what they consider earlier misguided decisions in the design of the packages comprising the \pkgname{tidyverse}. This is a wise decision for the future, but can be annoying to occasional users who may not be aware of the changes that have taken place between uses. As a user I highly value long-term stability and backwards compatibility of software. Older systems like base \Rlang provide this, but their long development history shows up as occasional inconsistencies and quirks. The \pkgname{tidyverse} as a paradigm is nowadays popular among data analysts while among users for whom data analysis is not the main focus, it is more common to make use of only individual packages as the need arises, e.g., using the new grammar only for some stages of the data analysis work flow.

When a computation included a chain of sequential operations, until \Rlang 4.1.0, using base \Rlang by itself we could either store the returned value in a temporary variable at each step in the computation, or nest multiple function calls. The first approach is verbose, but allows readable scripts, especially if the names used for temporary variables are wisely chosen. The second approach becomes very difficult too read as soon as there is more than one nesting level. Attempts to find an alternative syntax have borrowed the concept of data \emph{pipes} from Unix shells \autocite{Kernigham1981}. Interestingly, that it has been possible to write packages that define the operators needed to ``add'' this new syntax to \Rlang is a testimony to its flexibility and extensibility. Two packages, \pkgname{magrittr} and \pkgname{wrapr}, define operators for pipe-based syntax. In year 2021 a pipe operator was added to the \Rlang language itself and more recently its features enhanced.

In much of my work I emphasize reproducibility and reliability, preferring base \Rlang over extension packages, except for plotting, whenever practical. For run once and delete or quick-and-dirty data analyses I tend to use the \emph{tidyverse}. However, with modern computers and some understanding of what are the performance bottlenecks in \Rlang code, I have rarely found it worthwhile the effort needed for improved performance by using extension packages. The benefit to effort balance will be different for those readers who analyze huge data sets.

The definition of the \emph{tidyverse} is rather vague, as package \pkgname{tidyverse} loads and attaches a set of packages of which most but not all follow a consistent design and support this new grammar. In this chapter you will become familiar with packages \pkgname{tibble}, \pkgname{dplyr} and \pkgname{tidyr}. Package \pkgnameNI{ggplot2} will be described in chapter \ref{chap:R:plotting} as it implements the grammar of graphics and has little in common with other members of the \pkgname{tidyverse}. As many of the functions in the \emph{tidyverse} can be substituted by existing base \Rlang functions, recognizing similarities and differences between them has become important since both approaches are now in common use, and frequently even coexist within \Rlang scripts.

\begin{explainbox}
In any design, there is a tension between opposing goals. In software for data analysis a key pair of opposed goals are usability, including concise but expressive code, and avoidance of ambiguity. Base \Rlang function \Rfunction{subset()} has an unusual syntax, as it evaluates the expression passed as the second argument within the namespace of the data frame passed as its first argument (see \ref{sec:calc:df:with} on page \pageref{sec:calc:df:with}). This saves typing, enhancing usability, at the expense of increasing the risk of bugs, as by reading the call to subset, it is not obvious which names are resolved in the environment of the call to \code{subset()} and which ones within its first argument---i.e., as column names in the data frame. In addition, changes elsewhere in a script can change how a call to subset is interpreted. In reality, subset is a wrapper function built on top of the extraction operator \code{[ ]} (see section \ref{sec:calc:indexing} on page \pageref{sec:calc:indexing}). It is a convenience function, mostly intended to be used at the console, rather than in scripts or package code. To extract columns or rows from a data frame it is always safer to use the \Roperator{[ , ]} or \Roperator{[[ ]]} operators at the expense of some verbosity.

Package \pkgname{dplyr}, and much of the \pkgname{tidyverse}, relies on a similar approach as subset to enhance convenience at the expense of ambiguity. Package \pkgname{dplyr} has undergone quite drastic changes during its development history with respect to how to handle the dilemma caused by ``guessing'' of the environment where names should be looked up. There is no easy answer; a simplified syntax leads to ambiguity, and a fully specified syntax is verbose. Recent versions of the package introduced a terse syntax to achieve a concise way of specifying where to look up names. I do appreciate the advantages of the grammar of data that is implemented in the \pkgname{tidyverse}. However, the actual implementation, can result in ambiguities and subtleties that are even more difficult to deal by inexperienced or occasional users than those caused by inconsistencies in base \Rlang. My opinion is that for code that needs to be highly reliable and produce reproducible results in the future, we should for the time being prefer base \Rlang constructs. For code that is to be used once, or for which reproducibility can depend on the use of a specific (old or soon to become old) version of packages like \pkgname{dplyr}, or which is not a burden to thoroughly test and update regularly, the conciseness and power of the new syntax can be an advantage.
\end{explainbox}

\begin{infobox}
Package \pkgname{poorman} re-implements many of the functions in \pkgname{dplyr} and a few from \pkgname{tidyr} using pure \Rlang code instead of compiled \Cpplang code and with no dependencies on other extension packages. This light-weight approach can be useful when \Rlang's data frames rather than tibbles are preferred or when the possible enhanced performance with large data sets is not needed.
\end{infobox}

\section{Packages used in this chapter}

<<eval=FALSE>>=
install.packages(learnrbook::pkgs_ch_data)
@

To run the examples included in this chapter, you need first to load and attach some packages from the library (see section \ref{sec:script:packages} on page \pageref{sec:script:packages} for details on the use of packages).

<<message=FALSE>>=
library(learnrbook)
library(tibble)
library(magrittr)
library(wrapr)
library(stringr)
library(dplyr)
library(tidyr)
library(lubridate)
@

\section[Replacements for \texttt{data.frame}]{Replacements for \code{data.frame}}
\index{data frame!replacements|(}
\subsection{Package \pkgname{data.table}}
The function call semantics of the \Rlang language is that arguments are passed to functions by copy. If the arguments are modified within the code of a function, these changes are local to the function. If implemented naively, this semantic would impose a huge toll on performance, however, \Rlang in most situations only makes a copy in memory if and when the value changes. Consequently, for modern versions of \Rlang which are very good at avoiding unnecessary copying of objects, the normal \Rlang semantics has only a moderate negative impact on performance. However, this impact can still be a problem as modification is detected at the object level, and consequently \Rlang may make copies of large objects such as a whole data frame when only values in a single column or even just an attribute have changed.

Functions and methods from package \pkgname{data.table} pass arguments by reference, avoiding making any copies. However, any assignments within these functions and methods modify the variables passed as arguments. This simplifies the needed tests for delayed copying and also by avoiding the need to make a copy of arguments, achieves the best possible performance. This is a specialized package but extremely useful when dealing with very large data sets. Writing user code, such as scripts, with \pkgname{data.table} requires a good understanding of the pass-by-reference semantics. Obviously, package \pkgname{data.table} makes no attempt at backwards compatibility with base-\Rlang \code{data.frame}.

In contrast to the design of package \pkgname{data.table}, the focus of the \pkgname{tidyverse} is not only performance. The design of this grammar has also considered usability. Design compromises have been resolved differently than in base \Rlang or \pkgname{data.table} and in some cases code written using base \Rlang can significantly outperform the \pkgname{tidyverse} and vice versa. There exist packages that implement a translation layer from the syntax of the \pkgname{tidyverse} into that of \pkgname{data.table} or relational database queries.

\subsection{Package \pkgname{tibble}}\label{sec:data:tibble}
\index{tibble!differences with data frames|(}

The authors of package \pkgname{tibble} describe their \Rclass{tbl} class as nearly backwards compatible with \Rclass{data.frame} and make it a derived class. This backwards compatibility is only partial so in some situations data frames and tibbles are not equivalent.

The class and methods that package \pkgname{tibble} defines lift some of the restrictions imposed by the design of base \Rlang data frames at the cost of creating some incompatibilities due to changed (improved) syntax for member extraction. Tibbles simplify the creation of ``columns'' of class \Rclass{list} and remove support for columns of class \Rclass{matrix}. Handling of attributes is also different, with no row names added by default. There are also differences in default behavior of both constructors and methods.

\emph{Although, objects of class \Rclass{tbl} can be passed as arguments to functions that expect data frames as input, these functions are not guaranteed to work correctly with tibbles as a result of the differences in syntax of some methods.}

\begin{warningbox}
It is easy to write code that will work correctly both with data frames and tibbles by avoiding constructs that behave differently. However, code that is syntactically correct according to the \Rlang language may fail to work as expected if a tibble is used in place of a data frame. Only functions tested to work correctly with both tibbles and data frames can be relied upon as compatible.

Being newer and not part of the \Rlang language, the packages in the \pkgname{tidyverse} are evolving fast with rather frequent changes that require edits to the code of scripts and packages that use them. For example, whether attributes set in tibbles by users are copied or not to returned values has changed with updates.
\end{warningbox}

\begin{explainbox}
That it has been possible to define tibbles as objects of a class derived from \Rclass{data.frame} reveals one of the drawbacks of the simple implementation of S3 object classes in \Rlang. Allowing this is problematic because the promise of compatibility implicit in a derived class is not always fulfilled. An independently developed method designed for data frames will not necessarily work correctly with tibbles, but in the absence of a specialized method for tibbles it will be used (dispatched) when the generic method is called with a tibble as argument.
\end{explainbox}

\begin{infobox}
One should be aware that although the constructor \Rfunction{tibble()} and conversion function \Rfunction{as\_tibble()}, as well as the test \Rfunction{is\_tibble()} use the name \Rclass{tibble}, the class attribute is named \code{tbl}. This is inconsistent with base \Rlang conventions, as it is the use of an underscore instead of a dot in the name of these methods.

<<tibble-info-01>>=
my.tb <- tibble(numbers = 1:3)
is_tibble(my.tb)
inherits(my.tb, "tibble")
class(my.tb)
@

Furthermore, to support tibbles based on different underlying data sources such as \code{data.table} objects or databases, a further derived class is needed. In our example, as our tibble has an underlying \code{data.frame} class, the most derived class of \code{my.tb} is \Rclass{tbl\_df}.
\end{infobox}

We define a function that concisely reports the class of the object passed as argument and of its members (\emph{apply} functions are described in section \ref{sec:data:apply} on page \pageref{sec:data:apply}).

<<tibble-01>>=
show_classes <- function(x) {
  cat(
    paste(paste(class(x)[1],
    "containing:"),
    paste(names(x),
          sapply(x, class), collapse = ", ", sep = ": "),
    sep = "\n")
    )
}
@

The \Rfunction{tibble()} constructor by default does not convert character data into factors, while the \Rfunction{data.frame()} constructor did before \Rlang version 4.0.0. The default can be overridden through an argument passed to these constructors, and in the case of \Rfunction{data.frame()} also by setting an \Rlang option. This new behaviour extends to function \Rfunction{read.table()} and its wrappers (see section \ref{sec:files:txt} on page \pageref{sec:files:txt}).

<<tibble-02>>=
my.df <- data.frame(codes = c("A", "B", "C"), numbers = 1:3, integers = 1L:3L)
is.data.frame(my.df)
is_tibble(my.df)
show_classes(my.df)
@

Tibbles are, or pretend to be (see above), data frames---or more formally class \Rclass{tibble} is derived from class \code{data.frame}. However, data frames are not tibbles.

<<tibble-03>>=
my.tb <- tibble(codes = c("A", "B", "C"), numbers = 1:3, integers = 1L:3L)
is.data.frame(my.tb)
is_tibble(my.tb)
show_classes(my.tb)
@

The \Rmethod{print()} method for tibbles differs from that for data frames in that it outputs a header with the text ``A tibble:'' followed by the dimensions (number of rows $\times$ number of columns), adds under each column name an abbreviation of its class and instead of printing all rows and columns, a limited number of them are displayed. In addition, individual values are formatted more compactly and using color to highlight, for example, negative numbers in red.

<<tibble-04>>=
print(my.df)
print(my.tb)
@

\begin{explainbox}
The default number of rows printed depends on \Rlang option \code{tibble.print\_max} that can be set with a call to \Rfunction{options()}. This option plays for tibbles a similar role as option \code{max.print} plays for base \Rlang \Rmethod{print()} methods.

<<tibble-print-02>>=
options(tibble.print_max = 3, tibble.print_min = 3)
@
\end{explainbox}

\begin{playground}
Print methods for tibbles and data frames differ in their behaviour when not all columns fit in a printed line. 1) Construct a data frame and an equivalent tibble with at least 50 rows and then test how the output looks when they are printed. 2) Construct a data frame and an equivalent tibble with more columns than will fit in the width of the \Rlang console and then test how the output looks when they are printed.
\end{playground}

Data frames can be converted into tibbles with \code{as\_tibble()}.

<<tibble-05>>=
my_conv.tb <- as_tibble(my.df)
is.data.frame(my_conv.tb)
is_tibble(my_conv.tb)
show_classes(my_conv.tb)
@

Tibbles can be converted into ``real'' data.frames with \code{as.data.frame()}.

<<tibble-06>>=
my_conv.df <- as.data.frame(my.tb)
is.data.frame(my_conv.df)
is_tibble(my_conv.df)
show_classes(my_conv.df)
@

\begin{explainbox}
Not all conversion functions work consistently when converting from a derived class into its parent. The reason for this is disagreement between authors on what the \emph{correct} behavior is based on logic and theory. You are not likely to be hit by this problem frequently, but it can be difficult to diagnose.

We have already seen that calling \Rfunction{as.data.frame()} on a tibble strips the derived class attributes, returning a data frame. We will look at the whole character vector stored in the \code{"class"} attribute to demonstrate the difference. We also test the two objects for equality, in two different ways. Using the operator \code{==} tests for equivalent objects. Objects that contain the same data. Using \Rfunction{identical()} tests that objects are exactly the same, including attributes such as \code{"class"}, which we retrieve using \Rfunction{class()}.

<<tibble-box-01>>=
class(my.tb)
class(my_conv.df)
my.tb == my_conv.df
identical(my.tb, my_conv.df)
@

Now we derive from a tibble, and then attempt a conversion back into a tibble.

<<tibble-box-02>>=
my.xtb <- my.tb
class(my.xtb) <- c("xtb", class(my.xtb))
class(my.xtb)
my_conv_x.tb <- as_tibble(my.xtb)
class(my_conv_x.tb)
my.xtb == my_conv_x.tb
identical(my.xtb, my_conv_x.tb)
@

The two viewpoints on conversion functions are as follows. 1) The conversion function should return an object of its corresponding class, even if the argument is an object of a derived class, stripping the derived class. 2) If the object is of the class to be converted to, including objects of derived classes, then it should remain untouched. Base \Rlang follows, as far as I have been able to work out, approach 1). Some packages in the \pkgname{tidyverse} sometimes follow, or have followed in the past, approach 2). If in doubt about the behavior of some function, then you will need to do a test similar to the one used in this box.

As tibbles have been defined as a class derived from \code{data.frame}, if methods have not been explicitly defined for tibbles, the methods defined for data frames are called, and these are likely to return a data frame rather than a tibble. Even a frequent operation like column binding is affected, at least at the time of writing.

<<tibble-box-03>>=
class(my.df)
class(my.tb)
class(cbind(my.df, my.tb))
class(cbind(my.tb, my.df))
class(cbind(my.df, added = -3:-1))
class(cbind(my.tb, added = -3:-1))
identical(cbind(my.tb, added = -3:-1), cbind(my.df, added = -3:-1))

@
\end{explainbox}

There are additional important differences between the constructors \Rfunction{tibble()} and \code{data.frame()}. One of them is that in a call to \Rfunction{tibble()}, member variables (``columns'')  being defined can be used in the definition of subsequent member variables.

<<tibble-07>>=
tibble(a = 1:5, b = 5:1, c = a + b, d = letters[a + 1])
@

\begin{playground}
What is the behavior if you replace \Rfunction{tibble()} by \Rfunction{data.frame()} in the statement above?
\end{playground}

\begin{warningbox}
While objects passed directly as arguments to the \Rfunction{data.frame()} constructor to be included as ``columns'' can be factors, vectors or matrices (with the same number of rows as the data frame), arguments passed to the \Rfunction{tibble()} constructor can be factors, vectors or lists (with the same number of members as rows in the tibble). As we saw in section \ref{sec:R:data:frames} on page \pageref{sec:R:data:frames}, base \Rlang's data frames can contain columns of classes \code{list} and \code{matrix}. The difference is in the need to use \Rfunction{I()}, the identity function, to protect these variables during construction and assignment to true \code{data.frame} objects as otherwise list members and matrix columns will be assigned to multiple individual columns in the data frame.

<<tibble-08>>=
tibble(a = 1:5, b = 5:1, c = list("a", 2, 3, 4, 5))
@

A list of lists or a list of vectors can be directly passed to the constructor.

<<tibble-09>>=
tibble(a = 1:5, b = 5:1, c = list("a", 1:2, 0:3, letters[1:3], letters[3:1]))
@
\end{warningbox}

\index{tibble!differences with data frames|)}
\index{data frame!replacements|)}

\section{Data pipes}\label{sec:data:pipes}
\index{chaining statements with \emph{pipes}|(}
The first obvious difference between scripts using \pkgname{tidyverse} packages is the frequent use of \emph{pipes}. This is, however, mostly a question of preferences, as pipes can be as well used with base \Rlang functions. In addition, since version 4.0.0, \Rlang has a native pipe operator \Roperator{\textbar >}, described in section \ref{sec:script:pipes} on page \pageref{sec:script:pipes}. Here we describe other earlier implementations of pipes, and the differences among these and \Rlang's pipe operator.

\subsection{\pkgname{magrittr}}
\index{pipes!tidyverse|(}
\index{pipe operator}
A set of operators for constructing pipes of \Rlang functions is implemented in package \pkgname{magrittr}. It preceded the native \Rlang pipe by several years. The pipe operator defined in package \pkgname{magrittr}, \Roperator{\%>\%}, is imported and re-exported by package \pkgname{dplyr}, which in turn defines functions that work well in data pipes.

Operator \Roperator{\%>\%} plays a similar role as \Rlang's \Roperator{\textbar >}.

<<pipes-x00>>=
data.in <- 1:10
@

<<pipes-x04>>=
data.in %>% sqrt() %>% sum() -> data0.out
@

The value passed can be made explicit using a dot as placeholder passed as an argument by name and by position to the function on the \emph{rhs} of the \Roperator{\%>\%} operator. Thus \code{.} in \pkgname{magrittr} plays a similar but not identical role as \code{\_} in base \Rlang pipes.

<<pipes-x04a>>=
data.in %>% sqrt(x = .) %>% sum(.) -> data1.out
all.equal(data0.out, data1.out)
@

R's native pipe operator requires, consistently with \Rlang in all other situations, that functions that are to be evaluated use the parenthesis syntax, while \pkgname{magrittr} allows the parentheses to be missing when the piped argument is the only one passed to the function call on \textit{rhs}.

<<pipes-x04b>>=
data.in %>% sqrt %>% sum -> data5.out
all.equal(data0.out, data5.out)
@

Package \pkgname{magrittr} provides additional pipe operators, such as ``tee'' (\Roperator{\%T>\%}) to create a branch in the pipe, and \Roperator{\%<>\%} to apply the pipe by reference. These operators are much less frequently used than \Roperator{\%>\%}.
\index{pipes!tidyverse|)}

\subsection{\pkgname{wrapr}}
\index{pipes!wrapr|(}
\index{dot-pipe operator}
The \Roperator{\%.>\%}, or ``dot-pipe'', operator from package \pkgname{wrapr}, allows expressions both on the rhs and lhs, and \emph{enforces the use of the dot} (\code{.}), as placeholder for the piped object. Given the popularity of \pkgname{dplyr} the pipe operator from \pkgname{magrittr} has been the most used.

Rewritten using the dot-pipe operator, the pipe in the previous chunk becomes

<<pipes-x05>>=
data.in %.>% sqrt(.) %.>% sum(.) -> data2.out
all.equal(data0.out, data2.out)
@

However, as operator \Roperator{\%>\%} from \pkgname{magrittr} recognizes the \code{.} placeholder without enforcing its use, the code below where \Roperator{\%.>\%} is replaced by \Roperator{\%>\%} returns the same value as that above.

<<pipes-x05a>>=
data.in %>% sqrt(.) %>% sum(.) -> data3.out
all.equal(data0.out, data3.out)
@

\begin{infobox}
To use operator \Roperator{\textbar >} from \Rlang, we need to edit the code using (\code{\_}) as placeholder and passing it as argument to parameters by name in the function calls on the \textit{rhs}.

<<pipes-x05b>>=
data.in |> sqrt(x = _) |> sum(x = _) -> data4.out
all.equal(data0.out, data4.out)
@

We can, in this case, simply use no placeholder, and pass the arguments by position to the first parameter of the functions.

<<pipes-x05c>>=
data.in |> sqrt() |> sum() -> data4.out
all.equal(data0.out, data4.out)
@

\end{infobox}

The \index{pipes!expressions in rhs} dot-pipe operator \Roperator{\%.>\%} from \pkgname{wrapr} allows us to use the placeholder \code{.} in expressions on the \emph{rhs} of operators in addition to in function calls.

<<pipes-x07>>=
data.in %.>% (.^2) -> data7.out
@

In contrast, operators \Roperator{\textbar >} and \Roperator{\%>\%} do not support expressions, only function call syntax on their \textit{rhs}, forcing us to call operators with parenthesis syntax and named arguments

<<pipes-x07a>>=
data.in |> `^`(e1 = _, e2 = 2) -> data8.out
all.equal(data7.out, data8.out)
@

or

<<pipes-x07b>>=
data.in %>% `^`(e1 = ., e2 = 2) -> data9.out
all.equal(data7.out, data9.out)
@

In conclusion, \Rlang syntax for expressions is preserved when using the dot-pipe operator from \pkgname{wrapr}, with the only caveat that because of the higher precedence of the \Roperator{\%.>\%} operator, we need to ``protect'' bare expressions containing other operators by enclosing them in parentheses. In the examples above we showed a simple expression so that it could be easily converted into a function call. The \Roperator{\%.>\%} operator supports also more complex expressions, even with multiple uses of the placeholder.

<<pipes-x07c>>=
data.in %.>% (.^2 + sqrt(. + 1))
@

\subsection{Comparing pipes}

Under-the-hood, the implementations of operators  \Roperator{\textbar >} and \Roperator{\%>\%} and \Roperator{\%.>\%} are different, with \Roperator{\textbar >} expected to have the best performance, followed by \Roperator{\%.>\%} and \Roperator{\%>\%} being slowest. As implementations evolve, performance may vary among versions. However, \Roperator{\textbar >} being part of \Rlang is likely to remain the fastest.

Being part of the \Rlang language, \Roperator{\textbar >} will remain available and most likely also backwards compatible, while packages could be abandoned or redesigned by their maintainers. For this reason, it is preferable to use the \Roperator{\textbar >} in scripts or code expected to be reused, unless compatibility with \Rlang versions earlier than 4.2.0 is needed.

In the rest of the book when possible I will use \Rlang's pipes and use in examples the \code{\_} placeholder to facilitate understanding. In most cases the examples can be easily rewritten using operator \Roperator{\%>\%}.

Pipes can be used with any \Rlang function, but how elegant can be their use depends on the order of formal parameters. This is especially the case when passing arguments implicitly to the first parameter of the function on the \emph{rhs}. Several of the functions and methods defined in \pkgnameNI{tidyr}, \pkgnameNI{dplyr}, and a few other packages from the \pkgname{tidyverse} fit this need.

Writing a series of statements and saving intermediate results in temporary variables makes debugging easiest.  Debugging pipes is not as easy, as this usually requires splitting them, with one approach being the insertion of calls to \Rfunction{print()}. This is possible, because \Rfunction{print()} returns its input invisibly in addition to displaying it.

<<pipes-x08>>=
data.in |> print() |> sqrt() |> print() |> sum() |> print() -> data10.out
data10.out
@

Debugging nested function calls is the most difficult as well as code using such calls is difficult to read. So, in general, it is good to use pipes instead of nested function calls. However, it is best to avoid very long pipes. Normally while writing scripts or analysing data it is important to check the correctness of intermediate results, so saving them to variables can save time and effort.

The design of \Rlang's native pipes has benefited from the experience gathered by earlier implementations and being now part the language, we can expect it to become the reference one once its implementation is stable. The designers of the three implementations have to some extent disagreed in their design decisions. Consequently, some differences are more than aesthetic. \Rlang pipes are simpler, easier to use and expected to be fastest. Those from \pkgname{magrittr} are the most feature rich, but not as safe to use, and purportedly given a more complex implementation, the slowest. Package \pkgname{wrapr} is an attempt to enhance pipes compared to \pkgname{magrittr} focusing in syntactic simplicity and performance. \Rlang's \Roperator{\textbar >} operator has been enhanced since its addition in \Rlang only two years ago. These enhancements have all been backwards compatible.

The syntax of operators \Roperator{\textbar >} and \Roperator{\%>\%} is not identical. With \Rlang's \Roperator{\textbar >} (as of R 4.3.0) the placeholder \code{\_} can be only passed to parameters by name, while with \pkgname{magrittr}'s \Roperator{\%>\%} the placeholder \code{.} can be used to pass arguments both by name and by position. With operator \Roperator{\%.>\%} the use of the placeholder \code{.} is mandatory, and it can be passed by name or by position to the function call on the \textit{rhs}. Other differences are deeper like those related to the use in the \emph{rhs} of the extraction operator or support or not for expressions that are not explicit function calls.

In the case of \Rlang, the pipe is conceptually a substitution with no alteration of the syntax or evaluation order. This avoids \emph{surprising} the user and simplifies implementation. In other words, \Rlang pipes are an alternative way of writing nested function calls. Quoting \Rlang documentation:

\begin{quotation}
  Currently, pipe operations are implemented as syntax transformations. So an expression written as \code{x |> f(y)} is parsed as \code{f(x, y)}. It is worth emphasizing that while the code in a pipeline is written sequentially, regular \Rlang semantics for evaluation apply and so piped expressions will be evaluated only when first used in the rhs expression.
\end{quotation}

While frequently the different pipe operators can substitute for each other by adjusting the syntax, in some cases the differences among them in the order and timing of evaluation of the terms needs to be taken into account.

\begin{warningbox}
In some situations operator \Roperator{\%>\%} from package \pkgname{magrittr} can behave unexpectedly. One example is the use of \Rfunction{assign()} in a pipe. With \Rlang's operator \Roperator{\textbar >} assignment takes place as expected.

<<pipes-clean, include=FALSE>>=
rm(data6.out, data7.out, data8.out)
@

<<pipes-x06>>=
data.in |> assign(x = "data6.out", value = _)
all.equal(data.in, data6.out)
@

Named arguments are also supported with the dot-pipe operator from \pkgname{wrapr}.

<<pipes-x06a>>=
data.in %.>% assign(x = "data7.out", value = .)
all.equal(data.in, data7.out)
@

However, the pipe operator (\Roperator{\%>\%}) from package \pkgname{magrittr} silently and unexpectedly fails to assign the value to the name.

<<pipes-x06b>>=
data.in %>% assign(x = "data8.out", value = .)
if (exists("data8.out")) {
  all.equal(data.in, data8.out)
} else {
  print("'data8.out' not found!")
}
@

Although there are usually alternatives to get the computations done correctly, unexpected silent behaviour is not easy to deal with.
\end{warningbox}

\index{pipes!wrapr|)}
\index{chaining statements with \emph{pipes}|)}

\section{Reshaping with \pkgname{tidyr}}
\index{reshaping tibbles|(}
\index{long-form- and wide-form tabular data}
Data stored in table-like formats can be arranged in different ways. In base \Rlang most model fitting functions and the \Rfunction{plot()} method using (model) formulas and when accepting data frames, expect data to be arranged in ``long form'' so that each row in a data frame corresponds to a single observation (or measurement) event on a subject. Each column corresponds to a different measured feature, or ancillary information like the time of measurement, or a factor describing a classification of subjects according to treatments or features of the experimental design (e.g., blocks). Covariates measured on the same subject at an earlier point in time may also be stored in a column. Data arranged in \emph{long form} has been nicknamed as ``tidy'' and this is reflected in the name given to the \pkgname{tidyverse} suite of packages. However, this longitudinal arrangement of data has been the \Rlang and \Slang preferred format since their inception. Data in which columns correspond to measurement events is described as being in a \emph{wide form}.

Although long-form data is and has been the most commonly used arrangement of data in \Rlang, manipulation of such data has not always been possible with concise \Rlang statements. The packages in the \pkgname{tidyverse} provide convenience functions to simplify coding of data manipulation, which in some cases, have, in addition, improved performance compared to base \Rlang---i.e., it is possible to code the same operations using only base \Rlang, but this may require more and/or more verbose statements.

Real-world data is rather frequently stored in wide format or even ad hoc formats, so in many cases the first task in data analysis is to reshape the data. Package \pkgname{tidyr} provides functions for reshaping data from wide to long form and \emph{vice versa}.

\begin{warningbox}
Package \pkgname{tidyr} replaced \pkgname{reshape2} which in turn replaced \pkgname{reshape}, while additionally the functions implemented in \pkgname{tidyr} have been replaced by new ones with different syntax and name. So, using these functions although convenient, has over a period of several years made necessary to revise or rewrite scripts and relearn how to carry out these operations. If one is a data analyst and uses these functions every day, then the cost involved is frequently tolerable or even desirable given the improvements. However, if as is the case with many users of \Rlang in applied fields, to whom this book is targeted, in the long run using stable features from base \Rlang is preferable. This does not detract from the advantages of using a clear workflow as emphasized by the proponents of the \emph{tidyverse}.
\end{warningbox}

%% replace iris with an example that is really ``wide''
We use in examples below the \Rdata{iris} data set included in base \Rlang. Some operations on \Rlang \code{data.frame} objects with \pkgname{tidyverse} packages will return \code{data.frame} objects while others will return tibbles---i.e., \Rclass{"tb"} objects. Consequently it is safer to first convert into tibbles the data frames we will work with.

<<tidy-tibble-00>>=
iris.tb <- as_tibble(iris)
@

Function \Rfunction{pivot\_longer()} from \pkgname{tidyr} converts data from wide form into long form (or ''tidy''). We use it here to obtain a long-form tibble. By comparing \code{iris.tb} with \code{long\_iris.tb} we can appreciate how \Rfunction{pivot\_longer()} reshaped its input.

<<tidy-tibble-01>>=
long_iris.tb <-
  pivot_longer(iris.tb,
               cols = -Species,
               names_to = "part",
               values_to = "dimension")
long_iris.tb
@

\begin{infobox}
  Differently to base \Rlang, in most functions from the \pkgname{tidyverse} packages we can use bare column names preceded by a minus sign to signify ``all other columns''.
\end{infobox}

Function \Rfunction{pivot\_wider()} does not directly implement the exact inverse operation of \Rfunction{pivot\_longer()}. With multiple rows with shared codes, i.e., replication, in our case within each species and flower part, the returned tibble has columns that are lists of vectors. We need to expand these columns with function \Rfunction{unnest()} in a second step.

<<tidy-tibble-01a>>=
wide_iris.tb <-
  pivot_wider(long_iris.tb,
              names_from = "part",
              values_from = "dimension",
              values_fn = list) |>
  unnest(cols = -Species)
wide_iris.tb
@

\begin{playground}
Is \code{wide\_iris.tb} equal to \code{iris.tb}, the tibble we converted into long shape and back into wide shape? Run the comparisons below, and print the tibbles to find out.

<<tidy-tibble-pivot-pg01, eval=eval_playground>>=
identical(iris.tb, wide_iris.tb)
all.equal(iris.tb, wide_iris.tb)
all.equal(iris.tb, wide_iris.tb[ , colnames(iris.tb)])
@

What has changed? Would it matter if our code used indexing with a numeric vector to extract columns? or if it used column names as character strings?

\end{playground}

\begin{warningbox}
  Starting from version 1.0.0 of \pkgname{tidyr}, functions \Rfunction{gather()} and \Rfunction{spread()} are deprecated and replaced by functions \Rfunction{pivot\_longer()} and \Rfunction{pivot\_wider()}. These new functions, described above, use a different syntax than the old ones.
\end{warningbox}

%Base \Rlang function \Rfunction{reshape()} can do both operations, selected by passing it an argument. The names of the parameters are different and the manipulation of names is not built in as in the \pkgname{tidyr} functions.  Package \pkgname{poorman} provides a light-weight and dependency-free implementation of the core functions of package \pkgname{dplyr} and well as its own versions of functions \Rfunction{pivot\_longer()} and \Rfunction{pivot\_wider()}.
%
\begin{advplayground}
  Functions \Rfunction{pivot\_longer()} and \Rfunction{pivot\_wider()} from package \pkgname{poorman} attempt to replicate the behaviour of the same name functions from package \pkgname{tidyr}. In some edge cases, the behaviour differs. Test if the two code chunks above return identical or equal values when \code{poorman::}  is prepended to the names of these two functions. First, ensure than package \pkgname{poorman} is installed, then run the code below.

<<tidy-tibble-01c, eval=eval_playground>>=
poor_long_iris.tb <-
  poorman::pivot_longer(
    iris,
    cols = -Species,
    names_to = "part",
    values_to = "dimension")
identical(long_iris.tb, poor_long_iris.tb)
all.equal(long_iris.tb, poor_long_iris.tb)
class(long_iris.tb)
class(poor_long_iris.tb)
@

What is the difference between the values returned by the two functions? Could switching from package \pkgname{tidyr} to package \pkgname{poorman} affect code downstream of pivoting?
\end{advplayground}
\index{reshaping tibbles|)}

\section{Data manipulation with \pkgname{dplyr}}
\index{data manipulation in the tidyverse|(}

The first advantage a user of the \pkgname{dplyr} functions and methods sees is the completeness of the set of operations supported and the symmetry and consistency among the different functions. A second advantage is that almost all the functions are defined not only for objects of class \Rclass{tibble}, but also for objects of class \code{data.table} (package \pkgname{dtplyr}) and for SQL databases (package \pkgname{dbplyr}), with consistent syntax (see also section \ref{sec:data:db} on page \pageref{sec:data:db}). A downside of \pkgname{dplyr} and much of the \pkgname{tidyverse} is that the syntax is not yet fully stable. Additionally, some function and method names either override those in base \Rlang or clash with names used in other packages. \Rlang itself is extremely stable and expected to remain forward and backward compatible for a long time. For code intended to remain in use for years, the fewer packages it depends on, the less maintenance it will need. When using the \pkgname{tidyverse} we need to be prepared to revise our own dependent code after any major revision to the \pkgname{tidyverse} packages we use.

\subsection{Row-wise manipulations}
\index{row-wise operations on data|(}

Assuming that the data is stored in long form, row-wise operations are operations combining values from the same observation event---i.e., calculations within a single row of a data frame or tibble. Using functions \Rfunction{mutate()} and \Rfunction{transmute()} we can obtain derived quantities by combining different variables, or variables and constants, or applying a mathematical transformation. We add new variables (columns) retaining existing ones using \Rfunction{mutate()} or we assemble a new tibble containing only the columns we explicitly specify using \Rfunction{transmute()}.

\begin{explainbox}
Different from usual \Rlang syntax, with \Rfunction{tibble()}, \Rfunction{mutate()} and \Rfunction{transmute()} we can use values passed as arguments, in the statements computing the values passed as later arguments. In many cases, this allows more concise and easier to understand code.

<<tidy-tibble-02z>>=
tibble(a = 1:5, b = 2 * a)
@
\end{explainbox}

Continuing with the example from the previous section, we most likely would like to split the values in variable \code{part} into \code{plant\_part} and \code{part\_dim}. We use \code{mutate()} from \pkgname{dplyr} and \Rfunction{str\_extract()} from \pkgname{stringr}. We use regular expressions (see page \pageref{}) as arguments passed to \code{pattern}.  We do not show it here, but \Rfunction{mutate()} can be used with variables of any \code{mode}, and calculations can involve values from several columns. It is even possible to operate on values applying a lag or, in other words, using rows displaced relative to the current one.

<<tidy-tibble-02>>=
long_iris.tb %.>%
  mutate(.,
         plant_part = str_extract(part, "^[:alpha:]*"),
         part_dim = str_extract(part, "[:alpha:]*$")) -> long_iris.tb
long_iris.tb
@

In the next few chunks, we print the returned values rather than saving them in variables. In normal use, one would combine these functions into a pipe using operator \Roperator{\%.>\%} (see section \ref{sec:data:pipes} on page \pageref{sec:data:pipes}).

Function \Rfunction{arrange()} is used for sorting the rows---makes sorting a data frame or tibble simpler than by using \Rfunction{sort()} and \Rfunction{order()}. Here we sort the tibble \code{long\_iris.tb} based on the values in three of its columns.

<<tidy-tibble-03>>=
arrange(long_iris.tb, Species, plant_part, part_dim)
@

Function \Rfunction{filter()} can be used to extract a subset of rows---similar to \Rfunction{subset()} but with a syntax consistent with that of other functions in the \pkgname{tidyverse}. In this case, 300 out of the original 600 rows are retained.

<<tidy-tibble-04>>=
filter(long_iris.tb, plant_part == "Petal")
@

Function \Rfunction{slice()} can be used to extract a subset of rows based on their positions---an operation that in base \Rlang would use positional (numeric) indexes with the \code{[ , ]} operator: \code{long\_iris.tb[1:5, ]}.

<<tidy-tibble-05>>=
slice(long_iris.tb, 1:5)
@

Function \Rfunction{select()} can be used to extract a subset of columns--this would be done with positional (numeric) indexes with \code{[ , ]} in base \Rlang, passing them to the second argument as numeric indexes or column names in a vector. Negative indexes in base \Rlang can only be numeric, while \Rfunction{select()} accepts bare column names prepended with a minus for exclusion.

<<tidy-tibble-06>>=
select(long_iris.tb, -part)
@

In addition, \Rfunction{select()} as other functions in \pkgname{dplyr} accept ``selectors'' returned by functions \Rfunction{starts\_with()}, \Rfunction{ends\_with()}, \Rfunction{contains()}, and \Rfunction{matches()} to extract or retain columns. For this example we use the ``wide''-shaped \code{iris.tb} instead of \code{long\_iris.tb}.

<<tidy-tibble-06a>>=
select(iris.tb, -starts_with("Sepal"))
@

<<tidy-tibble-06b>>=
select(iris.tb, Species, matches("pal"))
@

Function \Rfunction{rename()} can be used to rename columns, whereas base \Rlang requires the use of both \Rfunction{names()} and \Rfunction{names()<-} and \emph{ad hoc} code to match new and old names. As shown below, the syntax for each column name to be changed is \code{<new name> = <old name>}. The two names can be given either as bare names as below or as character strings.

<<tidy-tibble-07>>=
rename(long_iris.tb, dim = dimension)
@
\index{row-wise operations on data|)}

\subsection{Group-wise manipulations}\label{sec:dplyr:group:wise}
\index{group-wise operations on data|(}

Another important operation is to summarize quantities by groups of rows. Contrary to base \Rlang, the grammar of data manipulation as implemented in \pkgname{dplyr}, makes it possible to split this operation into two steps: the setting of the grouping, and the calculation of summaries. This simplifies the code, making it more easily understandable when using pipes compared to the approach of base \Rlang \Rfunction{aggregate()}, and it also makes it easier to summarize several columns in a single operation.

The first step is to use \Rfunction{group\_by()} to ``tag'' a tibble with the grouping. We create a \emph{tibble} and then convert it into a \emph{grouped tibble}. Once we have a grouped tibble, function \Rfunction{summarise()} will recognize the grouping and use it when the summary values are calculated.

<<tibble-grouped-01>>=
tibble(numbers = 1:9, letters = rep(letters[1:3], 3)) %.>%
  group_by(., letters) %.>%
  summarise(.,
            mean_numbers = mean(numbers),
            median_numbers = median(numbers),
            n = n())
@

\begin{warningbox}
How is grouping implemented for data frames and tibbles?\index{grouping!implementation in tidyverse} In our case as our tibble belongs to class \code{tibble\_df}, grouping adds \code{grouped\_df} as the most derived class. It also adds several attributes with the grouping information in a format suitable for fast selection of group members. To demonstrate this, we need to make an exception to our recommendation above and save a grouped tibble to a variable.

<<tibble-grouped-box-01>>=
my.tb <- tibble(numbers = 1:9, letters = rep(letters[1:3], 3))
is.grouped_df(my.tb)
class(my.tb)
names(attributes(my.tb))
@

<<tibble-grouped-box-02>>=
my_gr.tb <- group_by(.data = my.tb, letters)
is.grouped_df(my_gr.tb)
class(my_gr.tb)
@
% allow page break
<<tibble-grouped-box-02a>>=
names(attributes(my_gr.tb))
setdiff(attributes(my_gr.tb), attributes(my.tb))
@

<<tibble-grouped-box-03>>=
my_ugr.tb <- ungroup(my_gr.tb)
class(my_ugr.tb)
names(attributes(my_ugr.tb))
@

<<tibble-grouped-box-04>>=
all(my.tb == my_gr.tb)
all(my.tb == my_ugr.tb)
identical(my.tb, my_gr.tb)
identical(my.tb, my_ugr.tb)
@

The tests above show that members are in all cases the same as operator \Roperator{==} tests for equality at each position in the tibble but not the attributes, while attributes, including \code{class} differ between normal tibbles and grouped ones and so they are not \emph{identical} objects.

If we replace \code{tibble} by \code{data.frame} in the first statement, and rerun the chunk, the result of the last statement in the chunk is \code{FALSE} instead of \code{TRUE}. At the time of writing starting with a \code{data.frame} object, applying grouping with \Rfunction{group\_by()} followed by ungrouping with \Rfunction{ungroup()} has the side effect of converting the data frame into a tibble. This is something to be very much aware of, as there are differences in how the extraction operator \Roperator{[ , ]} behaves in the two cases. The safe way to write code making use of functions from \pkgname{dplyr} and \pkgname{tidyr} is to always make sure that subsequent code works correctly with both tibbles and data frames.
\end{warningbox}
\index{group-wise operations on data|)}

\begin{infobox}
  In early 2023, package \pkgname{dplyr} version 1.1.0 added support for per-operation grouping by adding to functions a new parameter (\code{by} or \code{.by}). This is still considered an experimental feature that may change. Anyway, it is important to keep in mind that this approach to grouping is not persistent like that described above.
\end{infobox}

\subsection{Joins}
\index{joins between data sources|(}
\index{merging data from two tibbles|(}
Joins allow us to combine two data sources which share some variables. Variables in common are used to match the corresponding rows before ``joining'' variables (i.e., columns) from both sources together. There are several \emph{join} functions in \pkgname{dplyr}. They differ mainly in how they handle rows that do not have a match between data sources.

We create here some artificial data to demonstrate the use of these functions. We will create two small tibbles, with one column in common and one mismatched row in each.

<<tibble-print-10, echo=FALSE>>=
options(tibble.print_max = 6, tibble.print_min = 6)
@

<<joins-00>>=
first.tb <- tibble(idx = c(1:4, 5), values1 = "a")
second.tb <- tibble(idx = c(1:4, 6), values2 = "b")
@

Below we apply the \emph{}\index{joins between data sources!mutating} functions exported by \pkgname{dplyr}: \Rfunction{full\_join()}, \Rfunction{left\_join()}, \Rfunction{right\_join()} and \Rfunction{inner\_join()}. These functions always retain all columns, and in case of multiple matches, keep a row for each matching combination of rows. We repeat each example with the arguments passed to \code{x} and \code{y} swapped to more clearly show their different behavior.

A full join retains all unmatched rows filling missing values with \code{NA}. By default the match is done on columns with the same name in \code{x} and \code{y}, but this can be changed by passing an argument to parameter \code{by}. Using \code{by} one can base the match on columns that have different names in \code{x} and \code{y}, or prevent matching of columns with the same name in \code{x} and \code{y} (example at end of the section).

<<joins-01>>=
full_join(x = first.tb, y = second.tb)
@

<<joins-01a>>=
full_join(x = second.tb, y = first.tb)
@

Left and right joins retain rows not matched from only one of the two data sources, \code{x} and \code{y}, respectively.

<<joins-02>>=
left_join(x = first.tb, y = second.tb)
@

<<joins-02a>>=
left_join(x = second.tb, y = first.tb)
@

<<joins-03>>=
right_join(x = first.tb, y = second.tb)
@

<<joins-03a>>=
right_join(x = second.tb, y = first.tb)
@

An inner join discards all rows in \code{x} that do not have a matching row in \code{y} and \emph{vice versa}.

<<joins-04>>=
inner_join(x = first.tb, y = second.tb)
@

<<joins-04a>>=
inner_join(x = second.tb, y = first.tb)
@

Next we apply the \emph{filtering join}\index{joins between data sources!filtering} functions exported by \pkgname{dplyr}: \Rfunction{semi\_join()} and \Rfunction{anti\_join()}. These functions only return a tibble that always contains only the columns from \code{x}, but retains rows based on their match to rows in \code{y}.

A semi join retains rows from \code{x} that have a match in \code{y}.

<<joins-05>>=
semi_join(x = first.tb, y = second.tb)
@

<<joins-05a>>=
semi_join(x = second.tb, y = first.tb)
@

A anti-join retains rows from \code{x} that do not have a match in \code{y}.

<<joins-06>>=
anti_join(x = first.tb, y = second.tb)
@

<<joins-06a>>=
anti_join(x = second.tb, y = first.tb)
@

We here rename column \code{idx} in \code{first.tb} to demonstrate the use of \code{by} to specify which columns should be searched for matches.

<<joins-01b>>=
first2.tb <- rename(first.tb, idx2 = idx)
full_join(x = first2.tb, y = second.tb, by = c("idx2" = "idx"))
@
\index{merging data from two tibbles|)}
\index{joins between data sources|)}
\index{data manipulation in the tidyverse|)}

<<tibble-print-11, echo=FALSE>>=
options(tibble.print_max = 3, tibble.print_min = 3)
@

\section{Further reading}
An\index{further reading!new grammars of data} in-depth discussion of the \pkgname{tidyverse} is outside the scope of this book. Several books describe in detail the use of these packages. As several of them are under active development, recent editions of books such as \citebooktitle{Wickham2023} \autocite{Wickham2023} and \citebooktitle{Peng2022} \autocite{Peng2022} are the most useful.

<<echo=FALSE>>=
try(detach(package:lubridate))
try(detach(package:tidyr))
try(detach(package:dplyr))
try(detach(package:stringr))
try(detach(package:wrapr))
try(detach(package:magrittr))
try(detach(package:tibble))
try(detach(package:learnrbook))
@

<<eval=eval_diag, include=eval_diag, echo=eval_diag, cache=FALSE>>=
knitter_diag()
R_diag()
other_diag()
@
